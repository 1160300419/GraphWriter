Constrained minimization technique for topic identification using discriminative training and support vector machines .	latent semantic indexing matrix ; discrimina-tive training ; constrained minimization approach ; support vector machines ; banking call routing ; combination strategy ; classification error ; classification accuracy ; classifier accuracy ; switchboard databases ; vector-space model ; lsi matrix ; baseline classifiers ; score separation ; classifiers ; ensemble ; classifier ; accuracy	<method> <method> <method> <method> <task> <method> <task> <metric> <metric> <material> <method> <method> <method> <metric> <method> <method> <method> <metric>	17 5 16 ; 1 0 11 ; 2 0 11 ; 2 0 7 ; 1 0 6 ; 16 4 12 ; 17 5 12 ; 3 1 0 ; 14 1 2	this paper describes the <method_2> to combine multiple <method_14> in order to improve <metric_7> . since errors of individual <method_14> in the <method_15> should somehow be uncorrelated to yield higher <metric_7> , we propose a <method_5> where the combined <metric_8> is a function of the correlation between classification errors of the individual <method_14> . to obtain powerful single <method_14> , different techniques are investigated including <method_3> and <method_0> , which is a popular <method_10> . we also investigate <method_1> of the <method_11> on <method_2> . <method_1> minimizes the <task_6> by increasing the <metric_13> of the correct from competing documents . experimental evaluation is carried out on a <task_4> and on <material_9> with a set of 23 and 67 topics respectively . results show that the combined <method_16> we propose outperforms the <metric_17> of individual <method_12> by 44 % .	2 14 7 22 27 18 -1 15 5 8 18 -1 3 0 10 26 18 -1 1 11 20 21 18 -1 6 13 23 18 -1 18 -1 4 9 19 24 25 18 -1
Signfinder : Using Color to Detect , Localize and Identify Informational Signs .	illuminant color changes ; normalizing road signs ; stereotypical boundary shapes ; viewpoint direction ; uniform color ; shadowing ; occlusion ; illuminant	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 1 5 ; 5 1 6 ; 0 1 5 ; 3 1 6 ; 0 1 3	we describe an approach to detecting , locating and <task_1> . the approach will apply provided : -lrb- i -rrb- the signs have <otherscientificterm_2> -lrb- i.e. rectangular , or hexagonal -- of course , we allow for these shapes to be distorted by projection to unknown viewpoint -rrb- , -lrb- ii -rrb- the writing on the sign has one <otherscientificterm_4> and the rest of the sign has a second <otherscientificterm_4> -lrb- we allow for the color of the <otherscientificterm_7> to be unknown -rrb- . we show that the approach works even under significant <otherscientificterm_0> , <otherscientificterm_3> , <otherscientificterm_5> , and <otherscientificterm_6> . this work is part of a project intended to help people who are blind , or whose sight is impaired .	1 8 -1 2 4 7 8 -1 0 3 5 9 10 11 12 13 8 -1 6 8 -1
Joint Estimation of Motion , Structure and Geometry from Stereo Sequences .	simultaneous estimation of dense scene flow and structure ; normalisation of image and stereo constraints ; fully calibrated camera setup ; spatial and temporal information ; calibrated and uncalibrated data ; joint energy functional ; unknown stereo setup ; estimation of motion ; intrinsic camera parameters ; model assumptions ; discontinuity-preserving regularisation ; variational method ; simplified geometry ; rectified case ; stereo sequences ; accuracy	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <task> <material> <metric>	4 5 11 ; 11 0 0 ; 14 0 11	we present a novel <method_11> for the <task_0> from <material_14> . in contrast to existing approaches that rely on a <otherscientificterm_2> , we assume that only the <otherscientificterm_8> are known . to couple the <task_7> , structure and geometry , we propose a <otherscientificterm_5> that integrates <otherscientificterm_3> from two subsequent image pairs subject to an <otherscientificterm_6> . we further introduce a <otherscientificterm_1> such that deviations from <otherscientificterm_9> can be interpreted in a geometrical way . finally , we suggest a separate <method_10> to improve the <metric_15> . experiments on <material_4> demonstrate the excellent performance of our <method_11> . we even outperform recent techniques for the <task_13> that make explicit use of the <otherscientificterm_12> .	11 0 14 18 19 16 -1 2 8 16 -1 7 5 3 6 16 -1 1 9 16 -1 10 15 16 -1 4 17 16 -1 16 -1
Hierarchical language identification based on automatic language clustering .	hierarchical language identification framework ; ogi 10-language database ; gmm fusion system ; language identification ; single-level classification ; feature distribution ; fusion techniques ; multi-level classification ; features ; classification	<method> <material> <method> <task> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task>	7 2 0 ; 1 5 0 ; 1 5 2 ; 6 0 3	due to the limitation of <task_4> , existing <method_6> experience difficulty in improving the performance of <task_3> when the number of languages and <otherscientificterm_8> are further increased . given that the similarity of <otherscientificterm_5> between different languages may vary , we propose a novel <method_0> with <method_7> . in this <method_0> , target languages are hierarchically clustered into groups according to the distance between them , models are trained both for individual languages and language groups , and <task_9> is hierarchically done in multi-levels . this <method_0> is implemented and evaluated in this paper , the results showing an relative 15.1 % error-rate improvement in 30s case on <material_1> compared to modern <method_2> .	4 6 3 8 14 10 -1 5 0 7 11 10 -1 9 10 -1 12 13 10 -1
Differentially Private M-Estimators .	real world data set ; continuous and categorical variables ; privacy preserving m-estimators ; inference procedure ; statistical utility ; convergence rates ; perturbed histograms ; differential privacy ; m-estimators	<material> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method>	4 2 8 ; 7 2 8 ; 6 0 2 ; 7 1 4 ; 1 2 0	this paper studies <task_2> using <otherscientificterm_6> . the proposed approach allows the release of a wide class of <method_8> with both <otherscientificterm_7> and <otherscientificterm_4> without knowing a priori the particular <method_3> . the performance of the proposed method is demonstrated through a careful study of the <metric_5> . a practical algorithm is given and applied on a <material_0> containing both <otherscientificterm_1> .	2 6 12 9 -1 8 7 4 3 10 11 13 9 -1 5 9 -1 0 1 14 9 -1
The Kneed Walker for human pose tracking .	planar biomechanical characterization of human locomo-tion ; natural human walking speeds ; kneed walker prior ; 3d kinematic model ; joint limits ; kneed walker ; foot contact ; ground collisions ; cyclic gaits ; physics-based model ; step lengths ; monocular tracking ; measurement model ; constraints ; appearance ; hills ; occlusion	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 9 ; 9 0 11 ; 5 6 9 ; 7 1 4 ; 13 0 7	the <method_5> is a <method_9> derived from a <method_0> . by controlling torques at the knees , hips and torso , the <method_9> captures a full range of walking motions with <otherscientificterm_6> and balance . <otherscientificterm_13> are used to properly handle <task_7> and <otherscientificterm_4> . a prior density over walking motions is based on dynamics that are optimized for efficient <otherscientificterm_8> over a wide range of <otherscientificterm_1> and <otherscientificterm_10> , on different slopes . the <method_9> used for <task_11> comprises the <method_2> , a <method_3> constrained to be consistent with the underlying dynamics , and a simple <method_12> in terms of <otherscientificterm_14> and optical flow . the <method_5> is applied to people walking with varying speeds , on <otherscientificterm_15> , and with <otherscientificterm_16> .	5 9 0 18 20 17 -1 6 13 17 -1 7 4 21 22 17 -1 8 1 10 17 -1 11 2 3 12 19 17 -1 14 17 -1
Preference Completion : Large-scale Collaborative Ranking from Pairwise Comparisons .	rank r score matrix ; collaborative filtering datasets ; collaborative ranking setting ; large-scale non-convex implementation ; pairwise preferences ; pairwise data ; sample complexity ; pairwise information ; convex optimization ; factored form ; ranking ; minimization	<method> <material> <otherscientificterm> <method> <otherscientificterm> <material> <metric> <otherscientificterm> <method> <method> <task> <method>	0 0 5 ; 1 0 3	in this paper we consider the <otherscientificterm_2> : a pool of users each provides a small number of <otherscientificterm_4> between d possible items ; from these we need to predict each users preferences for items they have not yet seen . we do so by fitting a <method_0> to the <material_5> , and provide two main contributions : -lrb- a -rrb- we show that an algorithm based on <method_8> provides good generalization guarantees once each user provides as few as o -lrb- r log 2 d -rrb- pairwise comparisons -- essentially matching the <metric_6> required in the related matrix completion setting -lrb- which uses actual numerical as opposed to <otherscientificterm_7> -rrb- , and -lrb- b -rrb- we develop a <method_3> , which we call <method_3> , that trains a <method_9> of the matrix via alternating <method_11> -lrb- which we show reduces to alternating svm problems -rrb- , and scales and parallelizes very well to large problem settings . it also outper-forms common baselines on many moderately large popular <material_1> in both <method_3> and in other measures of <task_10> performance .	2 4 12 -1 0 5 8 6 13 12 -1 7 3 9 11 14 12 -1
A Graph Theoretic Approach for Object Shape Representation in Compositional Hierarchies Using a Hybrid Generative-Descriptive Model .	composi-tional hierarchy of parts ; minimum description length principle ; minimum conditional entropy clustering algorithm ; fast inference of part compositions ; benchmark two-dimensional shape image datasets ; frequent subgraph discovery problem ; hierarchical compositional architecture ; object shape representation ; hybrid generative-descriptive model ; graph theoretic approach ; shape retrieval methods ; discovered substructures ; vocabulary learning ; indexing mechanisms ; computational complexity ; part shareability ; descriptive parts ; shape retrieval ; shape representation ; part compositions ; statistical relationships	<method> <method> <method> <task> <material> <task> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <metric> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm>	13 0 3 ; 13 0 0 ; 9 0 7 ; 17 5 10 ; 8 0 12 ; 15 1 13 ; 2 0 20 ; 0 4 10 ; 15 0 0 ; 7 0 19 ; 0 0 17 ; 0 0 3 ; 0 6 6 ; 8 0 9 ; 15 0 3	a <method_9> is proposed for <method_7> in a <method_6> called <method_0> . in the proposed <method_9> , <method_12> is performed using a <method_8> . first , <otherscientificterm_20> between parts are learned using a <method_2> . then , selection of <otherscientificterm_16> is defined as a <task_5> , and solved using a <method_1> . finally , <otherscientificterm_19> are constructed by compressing the <method_7> with <otherscientificterm_11> . <method_18> and <metric_14> properties of the proposed <method_9> and algorithms are examined using six <material_4> . experiments show that <method_0> can employ <method_15> and <method_13> for <task_3> using learned shape vocabularies . additionally , <method_0> provides better <task_17> performance than the state-of-the-art <method_10> .	9 7 6 0 24 34 21 -1 12 8 26 35 21 -1 20 2 28 21 -1 16 5 1 21 -1 19 11 18 31 21 -1 14 4 21 -1 15 13 3 22 23 27 30 33 36 21 -1 25 29 32 21 -1
Efficient and secure encryption schemes for JPEG2000 .	encrypted packet body ; secure encryption algorithm ; jpeg 2000 ; jpeg2000 syntax ; encryption tools	<otherscientificterm> <method> <material> <otherscientificterm> <method>	1 0 1	the <otherscientificterm_3> requires that any two consecutive bytes in the <otherscientificterm_0> should not be larger than 0xff8f . this stringent requirement has plagued researchers for a few years and no satisfactory solution has been proposed . in this paper , we successfully developed efficient , secure and format-compliant encryption <method_1> for <material_2> . any <method_1> -lrb- stream cipher or block cipher -rrb- can be used in our <method_1> . the new <method_1> are remarkably efficient and introduce only extremely small amount of extra computation . the new <method_1> are highly secure and it is proved that <method_1> perfectly protect 99.15 % of the information of an image . the <method_4> described in this paper have been proposed to the jpsec -lrb- <material_2> security -rrb- standardization group .	3 0 5 -1 5 -1 1 2 5 -1 6 5 -1 5 -1 5 -1 5 -1
ProNet : Learning to Propose Object-Specific Boxes for Cascaded Neural Networks .	convolutional neural networks ; multi-scale fully-convolutional network ; bounding box annotations ; classification architecture pronet ; image regions ; neural networks ; object classification ; point-based localization ; arbitrary locations ; image-level annotations	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm>	5 0 3 ; 9 0 1 ; 3 0 4 ; 5 0 4 ; 3 0 7 ; 0 0 3 ; 6 1 7 ; 3 0 6	this paper aims to classify and locate objects accurately and efficiently , without using <otherscientificterm_2> . <method_3> is challenging as objects in the wild could appear at <otherscientificterm_8> and in different scales . in this paper , we propose a novel <method_3> based on <method_0> . <method_3> uses computationally efficient <method_5> to propose <otherscientificterm_4> that are likely to contain objects , and applies more powerful but slower <method_1> on the proposed regions . the basic building block is a <method_1> which assigns object confidence scores to boxes at different locations and scales . we show that such <method_1> can be trained effectively using <otherscientificterm_9> , and can be connected into cascades or trees for efficient <task_6> . <method_3> outperforms previous state-of-the-art significantly on pascal voc 2012 and ms coco datasets for <task_6> and <task_7> .	2 3 10 -1 8 10 -1 0 16 10 -1 5 4 1 11 13 14 10 -1 10 -1 12 10 -1 9 6 15 17 18 10 -1
Automated corpus callosum extraction via Laplace-Beltrami nodal parcellation and intrinsic geodesic curvature flows on surfaces .	intrinsic geometry of the white matter surface ; nontrivial laplace-beltrami eigenfunction ; corpus callosum ; t1-weighted structural mr images ; curve representation of cc ; zero level set ; white matter surface ; geodesic curvature flow ; finite element method ; human brain anatomy ; numerical schemes ; numerical solution ; triangular mesh ; curve ; contour ; accuracy	<otherscientificterm> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	2 6 9 ; 8 0 10	corpus callosum -lrb- cc -rrb- is an important structure in <otherscientificterm_9> . in this work , we propose a fully automated and robust approach to extract corpus callosum from <material_3> . the novelty of our method is composed of two key steps . in the first step , we find an initial guess for the <method_4> by using the <otherscientificterm_5> of the first <otherscientificterm_1> on the <otherscientificterm_6> . in the second step , the initial <otherscientificterm_13> is deformed toward the final solution with a <otherscientificterm_7> on the <otherscientificterm_6> . for <task_11> of the <otherscientificterm_7> on surfaces , we represent the <otherscientificterm_14> implicitly on a <otherscientificterm_12> and develop efficient <method_10> based on <method_8> . because our method depends only on the <otherscientificterm_0> , it is robust to orientation differences of the brain across population . in our experiments , we validate the proposed algorithm on 32 brains from a clinical study of multiple sclerosis disease and demonstrate that the <metric_15> of our results .	9 17 16 -1 3 16 -1 16 -1 4 5 1 6 16 -1 13 7 16 -1 11 18 16 -1 14 12 10 8 16 -1 0 16 -1
Kernelizing the output of tree-based methods .	biological network inference problem ; prediction of structured outputs ; tree-based ensemble methods ; image reconstruction task ; gram matrix ; tree-based methods ; input scalability ; learning sample ; regression trees ; irrelevant variables ; features ; interpretability ; kernel ; robustness	<task> <task> <method> <task> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	11 6 10 ; 9 1 6 ; 5 0 1 ; 13 1 6 ; 11 1 13	we extend <method_5> to the <task_1> using a kernelization of the algorithm that allows one to grow trees as soon as a <otherscientificterm_12> can be defined on the output space . the resulting algorithm , called output <otherscientificterm_12> trees -lrb- ok3 -rrb- , generalizes classification and <otherscientificterm_8> as well as <method_2> in a principled way . it inherits several <otherscientificterm_10> of these methods such as <otherscientificterm_11> , <metric_13> to <otherscientificterm_9> , and <metric_6> . when only the <otherscientificterm_4> over the outputs of the <otherscientificterm_7> is given , <otherscientificterm_4> learns the output <otherscientificterm_12> as a function of inputs . we show that the proposed algorithm works well on an <task_3> and on a <task_0> .	5 1 12 17 14 -1 8 2 14 -1 10 11 13 9 6 15 16 18 19 14 -1 4 7 14 -1 14 -1
Computing Layered Surface Representations : An Algorithm for Detecting and Separating Transparent Overlays .	consistent ` sidedness ; layered surface representations ; biological visual system ; layered surface structure ; local junction information ; image topology ; image intensity ; layered representation ; transparency labeling ; polarity-preserving junctions ; depth ordering ; surface attributes ; surface topology ; junctions ; images ; shading	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	2 0 1 ; 2 0 3 ; 12 1 5	the <method_2> possesses the ability to compute <method_1> , in which one surface is represented as being viewed through another . this ability is remarkable because , in scenes involving transparency , the link between <otherscientificterm_12> and <otherscientificterm_5> is greatly complicated by the collapse of the photometric contributions of two distinct surfaces onto <otherscientificterm_6> . previous analysis of transparency has focused largely on the role of different kinds of <otherscientificterm_13> . although <otherscientificterm_13> are important , <method_2> are not sufficient to predict <otherscientificterm_3> . we present an algorithm that propagates <otherscientificterm_4> by searching for chains of <otherscientificterm_9> with <otherscientificterm_0> , ' and then propagates the <otherscientificterm_8> into interior regions . the algorithm outputs a <method_7> specifying -lrb- i -rrb- the distinct surfaces , -lrb- ii -rrb- their <otherscientificterm_10> , and -lrb- iii -rrb- their <otherscientificterm_11> . we demonstrate the results of the algorithm on a number of <material_14> -- both synthetic and real . we end by considering implications for related domains , such as <otherscientificterm_15> .	2 1 17 16 -1 12 5 6 19 16 -1 13 16 -1 3 18 16 -1 4 9 0 16 -1 8 16 -1 7 10 11 16 -1 14 16 -1
Integrating parametric and non-parametric models for scene labeling .	convolutional neural networks ; ambiguity of local context ; road and sidewalk pixels ; global scene constraint ; visually similar pixels ; local patch classification ; global scene semantics ; visually dissimilar pixels ; sand pixels ; global potential ; energy function ; local view ; discriminative features ; parametric model ; classifiers	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	6 0 1 ; 0 0 12 ; 12 1 14 ; 9 0 10 ; 9 0 3 ; 14 0 5	we adopt <method_0> as our <method_13> to learn <otherscientificterm_12> and <method_14> for <task_5> . they are able to produce satisfactory labeling results for <otherscientificterm_7> . however , <method_0> struggle in <otherscientificterm_4> due to using their limited context . as shown in figure 1 , the <otherscientificterm_8> are highly confused with <otherscientificterm_2> in a <otherscientificterm_11> . we propose to utilize <otherscientificterm_6> to eliminate <otherscientificterm_1> , for example , the confusion between ` road ' and ` sand ' pixels in figure 1 can be easily removed if the '' coast '' scene is revealed . the <otherscientificterm_3> is achieved by adding a <otherscientificterm_9> to the <otherscientificterm_10> . the <otherscientificterm_10> is formally written as :	0 13 12 14 5 17 18 21 15 -1 7 15 -1 4 15 -1 8 2 11 15 -1 6 1 16 15 -1 3 19 20 15 -1 9 10 15 -1
View Synthesis by Appearance Flow .	convolutional neu-ral network ; 2-d coordinate vectors ; pixel copying task ; higher-quality synthesized views ; cnn-based techniques ; view synthesis ; camera transformations ; arbitrary viewpoint ; crisp texture	<method> <otherscientificterm> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 4 4 ; 0 0 5 ; 0 0 1 ; 5 4 5	given one or more images of an object -lrb- or a scene -rrb- , is <task_5> possible to synthesize a new image of the same instance observed from an <otherscientificterm_7> ? in this paper , we attempt to tackle this problem , known as novel <task_5> , by re-formulating <task_5> as a <task_2> that avoids the notorious difficulties of generating pixels from scratch . our <task_5> is built on the observation that the visual appearance of different views of the same instance is highly correlated . such <task_5> could be explicitly learned by training a <method_0> to predict appearance flows -- <otherscientificterm_1> specifying which pixels in the input view could be used to reconstruct the target view . we show that for both objects and scenes , our <task_5> is able to generate <otherscientificterm_3> with <otherscientificterm_8> and boundaries than previous <method_4> . fig. 1 . given an input view of an object -lrb- left -rrb- or a scene -lrb- right -rrb- , our goal is to synthesize novel views of the same instance corresponding to various <otherscientificterm_6> -lrb- ti -rrb- . our <task_5> based on learning appearance flows is able to generate higher-quality results than the previous <task_5> that directly outputs pixels in the target view -lsb- 1 -rsb- .	5 7 2 9 -1 9 -1 0 9 -1 1 11 12 9 -1 3 8 4 10 9 -1 9 -1 6 9 -1 13 9 -1
Identifying Sentiment Words Using an Optimization-based Model without Seed Words .	sentiment word identification ; sentiment labels of documents ; sentiment analysis applications ; low ro-bustness ; seed words ; optimization-based model ; real datasets	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <material>	5 0 1 ; 0 0 2 ; 5 0 0 ; 6 5 0	sentiment word identification -lrb- <task_0> -rrb- is a basic technique in many <task_2> . most existing researches exploit <otherscientificterm_4> , and lead to <otherscientificterm_3> . in this paper , we propose a novel <method_5> for <task_0> . unlike previous approaches , our <method_5> exploits the <otherscientificterm_1> instead of <otherscientificterm_4> . several experiments on <material_6> show that <task_0> is effective and outperforms the state-of-the-art methods with <otherscientificterm_4> .	0 2 9 7 -1 4 3 7 -1 5 10 7 -1 1 8 7 -1 6 11 7 -1
Linear predictive coding of myoelectric signals .	linear predictive coding paradigm ; simulated and experimental signals ; lossy coding technique ; surface emg signals ; mean frequency ; occupational medicine ; speech compression ; median frequency ; emg signals ; compression factor ; synthetic signals ; skewness ; bitrate ; variance ; ergonomics ; telemedicine ; kur-tosis	<method> <material> <method> <task> <metric> <task> <task> <metric> <material> <metric> <material> <metric> <metric> <metric> <task> <task> <metric>	4 1 13 ; 13 1 11 ; 7 1 11 ; 11 1 16 ; 0 0 2 ; 1 5 2 ; 14 1 5 ; 2 0 3 ; 13 1 16 ; 7 1 13 ; 0 0 6	despite the great interest towards long term recordings of electromyographic -lrb- emg -rrb- signals , which find applications for example in <task_15> , only a few studies have dealt with compression of these signals . in this paper we propose a <method_2> for <task_3> . the <method_2> is based on the <method_0> widely used for <task_6> . the <method_2> was tested on both <material_1> . <metric_4> , <metric_7> , <metric_13> , <metric_11> , and <metric_16> of the <material_8> were preserved with an error less than 3 % with respect to the original values for <material_10> and experimental signals , reducing the <metric_12> from 24 kbit/s -lrb- 12 kbit/s after downsampling -rrb- to 352 bit/s , with a <metric_9> of 97.1 % . it was concluded that the <method_0> can be effectively used for high rate compression of <task_3> when preservation of only the power spectrum of the signal is of interest . this has applications in <task_14> and <task_5> .	15 17 -1 2 3 25 17 -1 0 6 22 28 17 -1 1 4 23 17 -1 7 13 11 16 8 10 18 19 20 21 26 27 17 -1 12 9 17 -1 24 17 -1
Learning from Noisy Side Information by Generalized Maximum Entropy Model .	generalized maximum entropy model ; noisy side information ; maximum entropy model ; classification model ; theoretic analysis ; pairwise constraints ; paper citations ; side information ; data sources	<method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	5 2 1 ; 6 6 5 ; 6 6 8 ; 1 0 3 ; 8 0 5	we consider the problem of learning from <otherscientificterm_1> in the form of <otherscientificterm_5> . although many algorithms have been developed to learn from <otherscientificterm_7> , most of them assume perfect <otherscientificterm_5> . given the <otherscientificterm_5> are often extracted from <material_8> such as <otherscientificterm_6> , they tend to be noisy and inaccurate . in this paper , we introduce the generalization of <method_2> and propose a framework for learning from <otherscientificterm_1> based on the <method_0> . the <method_4> shows that under certain assumption , the <method_3> trained from the <otherscientificterm_1> can be very close to the one trained from the perfect <otherscientificterm_7> . extensive empirical studies verify the effectiveness of the proposed framework .	1 5 10 9 -1 7 9 -1 8 6 11 12 14 9 -1 2 0 9 -1 4 3 13 9 -1 9 -1
A Character n-gram Based Approach for Improved Recall in Indian Language NER .	entity recognition ; character n-gram based approach ; character n-gram based models ; named entity recognition systems ; date & time expressions ; word based models ; indian languages telugu ; dis-criminative model ; indian languages ; generative models ; english language ; organization names ; location names ; person names ; features ; hindi ; recall ; miscellaneous	<task> <method> <method> <method> <otherscientificterm> <method> <material> <method> <material> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <metric> <otherscientificterm>	12 1 4 ; 1 4 5 ; 11 1 12 ; 9 0 1 ; 13 1 11 ; 11 1 4 ; 13 1 12 ; 6 1 15 ; 2 4 5	named <task_0> is the task of identifying and classifying all proper nouns in a document as <otherscientificterm_13> , <otherscientificterm_11> , <otherscientificterm_12> , <otherscientificterm_4> and <otherscientificterm_17> . previous work -lrb- cucerzan and yarowsky , 1999 -rrb- was done using the complete words as <otherscientificterm_14> which suffers from a low <metric_16> problem . <method_1> -lrb- klein et al. , 2003 -rrb- using <method_9> , was experimented on <material_10> and <method_1> proved to be useful over the <method_5> . applying the same technique on <material_8> , we experimented with conditional random fields -lrb- crfs -rrb- , a <method_7> , and evaluated our system on two <material_6> and <material_15> . the <method_2> showed considerable improvement over the <method_5> . this paper describes the <otherscientificterm_14> used and experiments to increase the <metric_16> of <method_3> which is also language independent .	0 13 11 12 4 17 19 21 23 24 25 18 -1 14 16 1 18 -1 9 10 5 20 22 18 -1 8 7 26 18 -1 6 15 27 18 -1 2 18 -1
Structuring linear transforms for adaptation using training time information .	two-step bayesian approach ; speech recognition systems ; linear transforms ; training time ; expansion coefficients ; estimation algorithms ; test data ; subspace ; adaptation ; map ; covariances	<method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <task> <method> <otherscientificterm>	2 0 1 ; 2 0 8 ; 8 0 1 ; 5 0 8	linear transforms are often used for <task_8> to <material_6> in <task_1> . however , when used with small amounts of <material_6> , these techniques provide limited improvements if any . this paper proposes a <method_0> where a -rrb- the transforms lie in a <otherscientificterm_7> obtained at <otherscientificterm_3> and b -rrb- the <otherscientificterm_4> of the transform are obtained using <method_9> . <method_5> are given for <task_8> transforms for means , <otherscientificterm_10> , and feature spaces . experimental results indicate that our <method_0> gives a significant improvement in performance over other methods .	8 6 1 12 13 14 11 -1 11 -1 0 7 3 4 9 5 11 -1 10 15 11 -1 2 11 -1
3D scene flow estimation with a rigid motion prior .	local rigidity of the 3d scene ; realistic scenarios image motion ; 3d scene flow estimation ; agnostic smoothness priors ; rigid motion prior ; 3d scene flow ; local rigidity constraint ; rigidly moving parts ; 3d flow error ; energy minimization problem ; 3d motion ; total variation ; viewing direction ; scene structure ; tv regularization ; smoothness term ; observer motion	<otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	11 6 3 ; 6 0 5	we present an approach to <task_2> , which exploits that in <task_1> is frequently dominated by <otherscientificterm_16> and independent , but rigid object motion . we cast the dense estimation of both <otherscientificterm_13> and <otherscientificterm_10> from sequences of two or more views as a single <task_9> . we show that <otherscientificterm_3> , such as the popular <otherscientificterm_11> , are biased against motion discontinu-ities in <otherscientificterm_12> . instead , we propose to regularize by encouraging <otherscientificterm_0> . we derive a <otherscientificterm_6> of the <otherscientificterm_5> and define a <otherscientificterm_15> that penalizes deviations from that constraint , thus favoring solutions that consist largely of <otherscientificterm_7> . our experiments show that the new <otherscientificterm_4> reduces the <otherscientificterm_8> by 42 % compared to standard <task_14> with the same data term .	2 1 16 17 -1 13 10 9 17 -1 3 11 12 18 17 -1 0 17 -1 6 5 15 19 17 -1 7 17 -1
Guided Policy Search .	regularized importance sampled policy optimization ; guided policy search algorithm ; simulated 3d humanoid running ; direct policy search ; differential dynamic programming ; neural network controllers ; trajectory optimization ; policy search ; high-dimensional systems ; local optima ; policy learning ; planar swimming ; hopping	<method> <method> <task> <method> <method> <method> <method> <task> <method> <otherscientificterm> <task> <task> <task>	0 0 7 ; 6 0 1 ; 11 1 12 ; 5 0 11 ; 1 0 10 ; 5 0 1 ; 3 0 8	direct <task_7> can effectively scale to <method_8> , but complex policies with hundreds of parameters often present a challenge for such methods , requiring numerous samples and often falling into poor <otherscientificterm_9> . we present a <method_1> that uses <method_6> to direct <task_10> and avoid poor <otherscientificterm_9> . we show how <method_4> can be used to generate suitable guiding samples , and describe a <method_0> that incorporates these samples into the <task_7> . we evaluate the <method_1> by learning <method_5> for <task_11> , <task_12> , and walking , as well as <task_2> .	7 8 9 20 13 -1 1 6 10 15 18 13 -1 4 0 14 13 -1 5 11 12 2 3 16 17 19 13 -1
Exploiting simple hierarchies for unsupervised human behavior analysis .	analysis of human actions in visual scenes ; data-driven , hierarchical approach ; in-house assisted living ; unsupervised manner ; human interaction ; hierarchical stages ; semantic interpretation ; action level ; scene-specific adaptation ; hierarchical representation ; coupled tracking ; abnormality detection ; pre-trained models	<task> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <method> <task> <task> <method>	10 1 11 ; 7 0 9 ; 9 0 6 ; 1 0 10 ; 3 0 1 ; 1 0 11 ; 1 0 0	we propose a <method_1> for the <task_0> . in particular , we focus on the task of <task_2> . in such scenarios the environment and the setting may vary considerably which limits the performance of methods with <method_12> . therefore our <method_1> of normality is established in a completely <method_3> and is updated automatically for <task_8> . the <method_9> on both an appearance and an <otherscientificterm_7> paves the way for <task_6> . furthermore we show that the <method_1> is suitable for <task_10> and <task_11> on different <otherscientificterm_5> . as the experiments show , our <method_1> , simple yet effective , yields stable results , e.g. the detection of a fall , without any <otherscientificterm_4> .	1 0 20 13 -1 2 13 -1 12 13 -1 3 8 18 13 -1 9 7 6 15 16 13 -1 10 11 5 14 17 19 13 -1 13 -1
Curvature regularity for region-based image segmentation and inpainting : A linear programming relaxation .	curvature regularity of the region boundary ; integer linear program ; linear programming relaxation ; integer problem ; image segmentation ; region inte-grals ; region-based energies ; optimality gap ; region-based formulations ; higher-order regularity ; global optimum ; curvature regularity ; curvature regularity ; initialization ; thresholding ; segmentation	<otherscientificterm> <method> <task> <task> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task>	2 1 14 ; 6 0 4	we consider a class of <method_6> for <task_4> and inpainting which combine <otherscientificterm_5> with <otherscientificterm_0> . to minimize such energies , we formulate an <method_1> which jointly estimates regions and their boundaries . <otherscientificterm_11> is imposed by respective costs on pairs of adjacent boundary segments . by solving the associated <task_2> and <task_14> the solution one obtains an approximate solution to the original <task_3> . to our knowledge this is the first approach to impose <otherscientificterm_12> in <otherscientificterm_8> in a manner that is independent of <otherscientificterm_13> and allows to compute a bound on the optimal energy . in a variety of experiments on <task_15> and inpaint-ing , we demonstrate the advantages of <otherscientificterm_9> . moreover , we demonstrate that for most experiments the <otherscientificterm_7> is smaller than 2 % of the <otherscientificterm_10> . for many instances we are even able to compute the <otherscientificterm_10> .	6 4 5 0 18 16 -1 1 11 16 -1 16 -1 2 14 3 17 16 -1 12 8 13 16 -1 16 -1 15 9 16 -1 7 10 16 -1
Online Optimization in X-Armed Bandits .	generalization of stochastic bandit problems ; class of mean-payoff functions ; arm selection policy ; generic topological space ; dissimilarity function ; logarithmic factor ; unit hypercube ; mean-payoff function ; global maxima ; minimax optimality ; euclidean space ; lipschitz	<task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material>	10 2 6 ; 4 0 7	we consider a <task_0> where the set of arms , x , is allowed to be a <otherscientificterm_3> . we constraint the <otherscientificterm_7> with a <otherscientificterm_4> over x in a way that is more general than <material_11> . we construct an <method_2> whose regret improves upon previous result for a large class of problems . in particular , our results imply that if x is the <otherscientificterm_6> in a <otherscientificterm_10> and the <otherscientificterm_7> has a finite number of <otherscientificterm_8> around which the behavior of the function is locally hölder with a known exponent , then the expected regret is bounded up to a <otherscientificterm_5> by √ n , i.e. , the rate of the growth of the regret is independent of the dimension of the space . moreover , we prove the <method_9> of our algorithm for the <otherscientificterm_1> we consider .	0 3 12 -1 7 4 11 14 12 -1 2 12 -1 6 10 8 13 12 -1 5 12 -1
Segmentation of a Piece-Wise Planar Scene from Perspective Images .	segmenting feature points of piece-wise planar structures ; higher-dimensional real or complex space ; piece-wise planar scene ; closed-form segmentation solution ; real quadratic form ; complex bilinear form ; 2-d images ; subspace-segmentation methods ; algebraic properties ; 3-d reconstruction ; embedding methods ; homography ; homographies	<task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	5 2 11 ; 10 0 0 ; 6 2 2 ; 7 0 3 ; 4 2 11 ; 1 2 12 ; 5 1 4	we study and compare two novel <method_10> for <task_0> from two -lrb- uncalibrated -rrb- perspective images . we show that a set of different <otherscientificterm_12> can be embedded in different ways to a <otherscientificterm_1> , so that each <otherscientificterm_11> corresponds to either a <otherscientificterm_5> or a <otherscientificterm_4> . each embedding reveals different <otherscientificterm_8> and relations of homo-graphies . we give a <method_3> for each case by utilizing these properties based on <method_7> . these theoretical results show that one can intrinsically segment a <otherscientificterm_2> from <material_6> without explicitly performing any <method_9> . the resulting segmentation may make subsequent <method_9> much better-conditioned . we demonstrate the proposed methods with some convincing experimental results .	10 0 15 13 -1 12 1 11 5 4 14 18 19 20 13 -1 8 13 -1 3 7 17 13 -1 2 6 9 16 13 -1 13 -1 13 -1
Comparing parameter tying methods for multilingual acoustic modelling .	language dependent phoneme models ; speechdat databases ; continuous density hidden markov models ; bottom-up agglomerative clustering technique ; multilingual acoustic modelling ; sampa phone inventory ; multilingual phone models ; word recognition accuracy ; map language adaptation ; ld phoneme models ; model-level tying technique ; multilingual recognition systems ; dissimilarity measure ; european languages ; word accuracies ; multilingual recognition ; recognition rate ; state-level tying ; sampa ; accuracy ; tying	<method> <material> <method> <method> <task> <material> <method> <metric> <task> <method> <method> <method> <metric> <material> <metric> <task> <metric> <metric> <method> <metric> <task>	8 0 11 ; 10 0 0 ; 14 5 11 ; 11 0 6 ; 12 0 20 ; 16 5 11 ; 8 0 6 ; 2 0 4 ; 9 0 20 ; 3 0 20 ; 5 0 15 ; 12 0 9 ; 7 5 15	in this paper , we compare the state-level and model-level <task_20> of <method_2> for the <task_4> . using the <method_10> , the number of the <method_0> of five <material_13> were reduced to the desired number . this <task_20> was based on <metric_12> between the <method_9> in a <method_3> . this system provided 87.3 % <metric_7> on the test set , while a comparable <task_15> based on the <material_5> obtained 84.6 % <metric_19> on the same set . the above <method_10> was also used for obtaining an alternative phone inventory to <method_18> such that both inventories have an equal number of phones for these five languages . the <method_11> trained for the <method_18> and alternative phone inveton-ries obtained 80.9 % and 83.7 % <metric_14> on the same test set , when <metric_17> was used for reducing the number of the parameters from 199k to 76k in both systems . the original <method_11> obtained 89.0 % <metric_16> with the same test set , which contained approximately 200 isolated words from <material_1> for each of the five languages . in this paper , the test set results are also given for the <method_11> after performing <task_8> for the <method_6> .	20 2 4 29 21 -1 10 0 13 23 21 -1 12 9 3 26 30 31 33 21 -1 7 15 5 19 32 34 21 -1 18 21 -1 24 21 -1 11 14 17 27 21 -1 16 1 22 25 28 21 -1
Predictive vector quantization for wireless transmitter adaptation with limited feedback .	predictive vector quantization ; random vector quantization ; distributed transmitter adaptation ; b-bit codebook ; codebook element ; transmitter	<method> <method> <task> <otherscientificterm> <method> <otherscientificterm>	4 0 5 ; 0 4 1	in this paper we study <task_2> with limited feedback where a <otherscientificterm_3> known at both <otherscientificterm_5> and receiver is used in the update process . specifically , we discuss <method_0> where the <otherscientificterm_5> is updated incrementally using the <method_4> which results in smallest distortion in sum capacity from among the available 2 b codebook entries . the performance of the proposed <method_0> is compared with that of <method_1> with numerical results obtained from simulations .	2 3 5 6 -1 0 4 7 6 -1 1 8 6 -1
Multi-class semi-supervised SVMs with Positiveness Exclusive Regularization .	binary-class semi-supervised support vector machines ; positiveness exclusive regularization ; nesterov-type smoothing approximation based method ; regularized multi-task learning approach ; multi-class classification problem ; manifold regularization term ; joint framework ; one-vs-rest strategy ; 1,2-norm regularizer ; unlabeled sample ; visual classification ; semi-supervised setting ; per term ; regularization ; optimization ; classifiers ; s3vms	<method> <method> <method> <method> <task> <otherscientificterm> <method> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method>	11 2 4 ; 7 0 0 ; 12 1 5 ; 2 0 14 ; 8 0 1 ; 3 0 0	in this work , we address the problem of <task_4> in <otherscientificterm_11> . a <method_3> is presented to train multiple <method_0> using the <method_7> within a <method_6> . a novel type of <otherscientificterm_13> , namely <method_1> , is introduced to induce the following prior : if an <material_9> receives significant positive response from one of the <method_15> , it is less likely for this sample to receive positive responses from the other <method_15> . that is , we expect an exclusive relationship among different <method_16> for evaluating the same <material_9> . we propose to use an <method_8> as an implementation of <method_1> . the objective of our <method_3> is to minimize an empirical risk regularized by a <otherscientificterm_12> and a <otherscientificterm_5> . an efficient <method_2> is developed for <task_14> . evaluations with comparisons are conducted on several benchmarks for <task_10> to demonstrate the advantages of the proposed <method_3> .	4 11 18 17 -1 3 0 7 6 19 23 17 -1 13 1 9 15 17 -1 16 17 -1 8 22 17 -1 20 17 -1 12 5 21 17 -1 2 14 17 -1
Image Categorization Using Directed Graphs .	directed graph -lrb- asymmetric similarity ; graph-based semi-supervised classification methods ; computer vision tasks ; graph construction methods ; symmetric co-linkage similarity ; image cat-egorization ; structural information ; pairwise similarities ; edge weights ; image annotation ; object recognition ; asymmetric similarities ; directed graph ; undirected graph ; nodes ; symmetrization ; images ; graph	<otherscientificterm> <method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	7 0 1 ; 11 0 6 ; 4 0 5 ; 9 6 2 ; 10 1 9 ; 4 0 2 ; 10 6 5 ; 8 2 13 ; 10 6 2 ; 15 0 12 ; 2 0 5	most existing <method_1> use <otherscientificterm_7> as <otherscientificterm_8> of an <otherscientificterm_13> with <material_16> as the <otherscientificterm_14> of the <otherscientificterm_17> . recently several new <method_3> produce , however , <otherscientificterm_0> between <otherscientificterm_14> -rrb- . a simple <method_15> is often used to convert a <otherscientificterm_12> to an undirected one . this , however , loses important <otherscientificterm_6> conveyed by <otherscientificterm_11> . in this paper , we propose a novel <otherscientificterm_4> which captures the essential relationship among the <otherscientificterm_14> in the <otherscientificterm_12> . we apply this new <otherscientificterm_4> in two important <task_2> for <task_5> : <task_10> and <task_9> . extensive empirical studies demonstrate the effectiveness of our <otherscientificterm_4> .	1 7 8 13 16 14 17 19 26 18 -1 3 0 18 -1 15 12 28 18 -1 6 11 20 18 -1 4 18 -1 2 5 10 9 21 22 23 24 25 27 29 18 -1 18 -1
A Symbolic SAT-based Algorithm for Almost-sure Reachability with Small Strategies in POMDPs .	symbolic approach ; probabilistic planning problems ; almost-sure reachability ; belief-support mdp ; sat solver ; observation-stationary strategies ; symbolic algorithm ; small-memory strategies ; exponential reduction ; policy ; sat ; exptime-complete ; encoding ; pomdps	<method> <task> <task> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <method>	13 0 1 ; 12 0 6 ; 12 0 10	pomdps are standard models for <task_1> , where an agent interacts with an uncertain environment . we study the problem of <task_2> , where given a set of target states , the question is to decide whether there is a <otherscientificterm_9> to ensure that the target set is reached with probability 1 -lrb- almost-surely -rrb- . while in general the problem is <method_11> , in many practical cases policies with a small amount of memory suffice . moreover , the existing solution to the problem is explicit , which first requires to construct explicitly an <method_8> to a <otherscientificterm_3> . in this work , we first study the existence of <method_5> , which is np-complete , and then <method_7> . we present a <method_6> by an efficient <method_12> to <method_10> and using a <method_4> for the problem . we report experimental results demonstrating the scalability of our <method_0> .	1 15 14 -1 2 9 14 -1 11 14 -1 8 3 14 -1 14 -1 5 7 16 17 14 -1 6 12 10 4 14 -1
Categorical perception in intonation : a matter of signal dynamics ? .	phonological intonation categories ; f0 peak movements ; identification judgements ; signal dynamics ; intensity transitions ; german intonation ; categorical perception ; reaction times	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	1 1 4 ; 2 1 7 ; 6 0 0	results of recent perception experiments revealed that the signalling of rising-falling f0 peak categories in <material_5> involves an interplay of f0 and intensity . moreover , combining <otherscientificterm_2> and <otherscientificterm_7> suggests that the abruptness of the perceptual change between the categories is determined by the <otherscientificterm_3> in the sense of the durations of the <otherscientificterm_1> and <otherscientificterm_4> . this undermines the use of <otherscientificterm_6> as an instrument to detect <otherscientificterm_0> .	5 8 -1 2 7 3 1 4 9 10 8 -1 6 0 11 8 -1
Gap-filling by the empirical mode decomposition .	intrinsic mode functions ; empirical mode decomposition ; environmental pollutant data ; intrinsic mode functions ; missing data ; gap-filling technique	<material> <method> <material> <otherscientificterm> <material> <method>	2 5 5 ; 1 0 5	we propose a novel <method_5> , based on the <method_1> . the idea is that a signal with <material_4> can be decomposed into a set of <material_0> with <material_4> . filling the gaps in each <material_0> should be easier than filling the gaps in the original signal . this is because each <material_0> varies much more slowly than the original signal , and also because the <material_0> are known to have useful regularity properties . we demonstrate the performance of our <method_5> on <material_2> .	5 1 8 6 -1 4 0 6 -1 6 -1 6 -1 2 3 7 6 -1
QASR : question answering using semantic roles for speech interface .	open domain question answering task ; semantic role labeling approach ; semantic role labeling ; question answering system ; extraction of answers ; semantic argument phrases ; answering systems ; voice interfaces ; semantic parses ; predicates ; accuracy ; structure	<task> <method> <task> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	1 0 7 ; 10 5 1 ; 10 5 3 ; 2 0 9 ; 9 1 5 ; 1 0 0 ; 7 0 3 ; 1 0 4 ; 1 0 1 ; 1 0 3 ; 2 0 5	in this paper , we evaluate a <method_1> to the <task_4> in the <task_0> . we show that this <method_1> especially improves the <method_1> performance when answers are communicated to the user by voice . <task_2> identifies <otherscientificterm_9> and <otherscientificterm_5> in a sentence . with this information we are able to analyze and extract <otherscientificterm_11> from both questions and candidate sentences , which helps us identify more relevant and precise answers in a long list of candidate sentences . when searching for an answer to a question , we match the missing argument in the question to the <otherscientificterm_8> of the candidate answers . this <method_1> significantly improves the <metric_10> of the <method_3> and results in more concise and grammatical answers , which is essential for enabling <otherscientificterm_7> to question <method_6> . in this paper we apply our <method_1> to factoid questions containing <otherscientificterm_9> ; however , this <method_1> can be also useful in answering more complex questions .	1 4 0 18 20 12 -1 2 21 12 -1 9 5 16 17 23 12 -1 11 12 -1 8 12 -1 13 14 15 19 22 12 -1 10 3 7 6 12 -1
Self-Managing Associative Memory for Dynamic Acquisition of Expertise in High-Level Domains .	stream of incoming data ; higher-resolution collections of models ; high-resolution collections of models ; allocation of models ; high-level associative memory ; distribution of models ; fast learning ; high-resolution areas ; intelligent system ; self-organizing maps ; growth rate ; high-level domain ; som decay ; long-term memory ; associative memory ; high-level domains ; decay rate ; soms ; som	<material> <method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <metric> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <metric> <method> <method>	7 2 12 ; 9 0 14 ; 9 0 8 ; 17 0 4 ; 6 1 13 ; 14 0 8 ; 17 0 14	self-organizing maps can be used to implement an <otherscientificterm_14> for an <method_8> that dynamically learns about new <material_15> over time . <method_17> are an attractive option for implementing <otherscientificterm_14> : <method_17> are fast , easily parallelized , and digest a <material_0> into a topographically organized collection of models where more frequent classes of data are represented by <method_1> . typically , the <otherscientificterm_5> in an <method_18> , once developed , remains fairly stable , but developing expertise in a new <material_11> requires altering the <method_3> . we use a mixture of analysis and empirical studies to characterize the behavior of <method_17> for <otherscientificterm_4> , finding that new <task_2> develop quickly . <otherscientificterm_7> of the <otherscientificterm_12> rapidly unless actively refreshed , but in a large <method_18> , the ratio between <metric_10> and <metric_16> may be high enough to support both <method_6> and <otherscientificterm_13> .	14 8 15 17 21 22 25 19 -1 0 1 26 19 -1 5 18 11 3 19 -1 23 19 -1 4 2 7 20 24 19 -1
Deformable Template and Distribution Mixture-Based Data Modeling for the Endocardial Contour Tracking in an Echographic Sequence .	shape-based segmentation of de-formable anatomical structures ; real echocardiographic image sequence ; grey level distribution ; steepest ascent procedure ; echographic image sequence ; global prior knowledge ; data likelihood model ; genetic algorithm ; admissible deformations ; prototype template ; medical images ; optimization problem ; synthetic images ; statistical model-ing ; endocardial border ; endocardial contour ; tracking problem	<task> <material> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <material> <task> <material> <method> <otherscientificterm> <otherscientificterm> <task>	10 2 0 ; 9 0 15 ; 13 0 6 ; 8 2 9 ; 12 1 1 ; 3 5 7	we 1 present a new method to <task_0> in <material_10> and validate this approach by detecting and tracking the <otherscientificterm_14> in an <material_4> . to this end , a <otherscientificterm_5> of the <otherscientificterm_15> is captured by a <method_9> with a set of <otherscientificterm_8> to take into account its inherent natural variability over time . in this approach , the <method_6> rely on an accurate <method_13> of the <otherscientificterm_2> of each class present in the image . the parameters of this distribution mixture are given by a preliminary estimation step which takes into account the distribution shape of each class . then the <task_16> is stated in a bayesian framework where it ends up as an <task_11> . this one is then efficiently solved by a <method_7> combined with a <method_3> . this technique has been successfully applied on <material_12> and on a <material_1> .	0 10 14 4 18 17 -1 5 15 9 8 19 21 17 -1 6 13 2 20 17 -1 17 -1 17 -1 16 11 23 17 -1 7 3 22 17 -1
Identifying Relations for Open Information Extraction .	open information extraction ; syntactic and lexical constraints ; uninfor-mative and incoherent extractions ; reverb open ie system ; open ie systems ; woe pos ; massive corpora ; pre-specified vocabulary ; precision-recall curve ; binary relations ; textrunner	<task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	2 5 4 ; 10 1 5 ; 1 3 3	open information extraction -lrb- ie -rrb- is the task of extracting assertions from <material_6> without requiring a <otherscientificterm_7> . this paper shows that the output of state-of-the-art <method_4> is rife with <otherscientificterm_2> . to overcome these problems , we introduce two simple <otherscientificterm_1> on <otherscientificterm_9> expressed by verbs . we implemented the <otherscientificterm_1> in the <method_3> , which more than doubles the area under the <otherscientificterm_8> relative to previous extractors such as <method_10> and <otherscientificterm_5> . more than 30 % of reverb 's extractions are at precision 0.8 or higher -- compared to virtually none for earlier systems . the paper concludes with a detailed analysis of reverb 's errors , suggesting directions for future work .	6 7 11 -1 4 2 12 11 -1 1 9 11 -1 3 8 10 5 13 14 11 -1 11 -1 11 -1
Effective Phrase Translation Extraction from Alignment Models .	sentence and corpus level ; phrase level translation models ; phrase level knowledge sources ; global phrasal context ; alignment based method ; word based lexica ; ibm translation model ; local reordering ; translation quality ; ibm models ; noisy alignments ; bleu metric ; computational cost	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <metric> <method> <otherscientificterm> <metric> <metric>	9 0 2 ; 5 1 4 ; 1 0 8 ; 8 5 1	phrase level translation models are effective in improving <metric_8> by addressing the problem of <task_7> across language boundaries . methods that attempt to fundamentally modify the traditional <method_6> to incorporate phrases typically do so at a prohibitive <metric_12> . we present a technique that begins with improved <method_9> to create <otherscientificterm_2> that effectively represent local as well as <otherscientificterm_3> . our method is robust to <otherscientificterm_10> at both the <otherscientificterm_0> , delivering high quality phrase level translation pairs that contribute to significant improvements in <metric_8> -lrb- as measured by the <metric_11> -rrb- over <otherscientificterm_5> as well as a competing <method_4> .	8 7 16 17 13 -1 6 12 13 -1 9 2 3 14 13 -1 10 0 11 5 4 15 13 -1
Grammar specialisation meets language modelling .	medium vocabulary command and control task ; mixed initiative systems ; cfg-based language models ; explanation based learning ; language models ; commercial applications ; domain-independent descriptions ; cfg-based models ; high-level formalisms ; unification grammar ; specialised grammars ; domain-independent grammar ; cfg	<task> <task> <method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method>	7 0 1 ; 0 0 4 ; 6 0 2 ; 3 0 11 ; 10 0 4 ; 9 6 8 ; 2 0 5	cfg-based <method_4> have become popular over the last few years , especially for <task_5> , and there is growing interest in creating complex <method_7> for <task_1> . on general grounds , it is attractive to attempt to compile these <method_2> from <otherscientificterm_6> written in <otherscientificterm_8> such as <method_9> . experience to date however suggests that compilation from complex <method_9> to <method_12> has poor scalability properties . we argue that it is possible to attack this problem by first specialis-ing the <method_11> against a corpus using <method_3> . we describe experiments carried out on a <task_0> , which suggest that <method_4> derived from <method_10> have much better scalability properties , and also deliver significantly improved run-time performance .	4 5 7 1 14 20 13 -1 2 6 8 9 16 19 13 -1 12 13 -1 11 3 17 13 -1 0 15 18 13 -1
Reliable Patch Trackers : Robust visual tracking by exploiting reliable patches .	reliable patch trackers ; clustering of homo-trajectory patches ; sequential monte carlo framework ; tracking reliability metric ; hough voting-like scheme ; bounding box ; motion trajectories ; tracking process ; probability model ; visual object ; visual objects ; patch ; tracking ; initialization	<method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm>	4 0 1 ; 3 0 11 ; 1 0 9	most modern trackers typically employ a <otherscientificterm_5> given in the first frame to track <otherscientificterm_10> , where their <task_12> results are often sensitive to the <otherscientificterm_13> . in this paper , we propose a new <method_3> , <method_0> , which attempts to identify and exploit the reliable patches that can be tracked effectively through the whole <method_7> . specifically , we present a <method_3> to measure how reliably a <method_11> can be tracked , where a <method_8> is proposed to estimate the distribution of reliable patches under a <method_2> . as the reliable patches distributed over the image , we exploit the <otherscientificterm_6> to distinguish them from the background . therefore , the <otherscientificterm_9> can be defined as the <method_1> , where a <method_4> is employed to estimate the target state . encouraging experimental results on a large set of sequences showed that the proposed <method_3> is very effective and in comparison to the state-of-the-art trackers . the full source code of our implementation will be publicly available .	5 10 12 13 14 -1 3 0 7 14 -1 11 8 2 16 14 -1 14 -1 6 15 17 14 -1 9 1 4 14 -1 14 -1
Data-Driven Response Generation in Social Media .	phrase-based statistical machine translation ; twitter status posts ; conversational stimuli ; human evaluation ; unaligned words/phrases ; phrase-based smt ; information retrieval ; linguistic stimulus ; data-driven approach ; ir	<method> <material> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <method> <task>	5 1 6 ; 5 4 9 ; 0 0 8 ; 5 0 7 ; 8 0 1 ; 6 6 3	we present a <method_8> to generating responses to <material_1> , based on <method_0> . we find that mapping <otherscientificterm_2> onto responses is more difficult than translating between languages , due to the wider range of possible responses , the larger fraction of <otherscientificterm_4> , and the presence of large phrase pairs whose alignment can not be further decomposed . after addressing these challenges , we compare approaches based on <task_5> and <task_6> in a <task_3> . we show that <task_5> outperforms <task_9> on this task , and its output is preferred over actual human responses in 15 % of cases . as far as we are aware , this is the first work to investigate the use of <task_5> to directly translate a <otherscientificterm_7> into an appropriate response .	8 1 0 13 15 10 -1 2 4 10 -1 5 6 3 11 16 10 -1 9 12 10 -1 14 10 -1
A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel Learning .	o -lrb- log -lrb- d -rrb- -rrb- time ; low-variance estimates of the gradient ; simulated and real data ; mirror descent algorithm ; kernel learning methods ; randomized version ; polynomial kernel ; an-optimal solution ; exponential speed-up ; combinatorial structure ; sampling	<otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	2 5 3	we consider the problem of simultaneously learning to linearly combine a very large number of kernels and learn a good predictor based on the learnt kernel . when the number of kernels d to be combined is very large , multiple <method_4> whose computational cost scales linearly in d are intractable . we propose a <method_5> of the <method_3> to overcome this issue , under the objective of minimizing the group p-norm penalized empirical risk . the key to achieve the required <otherscientificterm_8> is the computationally efficient construction of <otherscientificterm_1> . we propose importance <method_10> based estimates , and find that the ideal distribution samples a coordinate with a probability proportional to the magnitude of the corresponding gradient . we show the surprising result that in the case of learning the coefficients of a <method_6> , the <otherscientificterm_9> of the base kernels to be combined allows the implementation of <method_10> from this distribution to run in <otherscientificterm_0> , making the total computational cost of the <method_3> to achieve <otherscientificterm_7> to be o -lrb- log -lrb- d -rrb- / / 2 -rrb- , thereby allowing our <method_3> to operate for very large values of d. experiments with <material_2> confirm that the new <method_3> is computationally more efficient than its state-of-the-art alternatives .	11 -1 4 11 -1 5 3 11 -1 8 1 11 -1 10 11 -1 12 11 -1
Multi-label Ranking from Positive and Unlabeled Data .	positive and unlabeled classification problem ; incomplete label assignment problems ; well-studied rank-based multi-label classification ; classical binary pu problems ; multi-label pu ranking ; binary setting ; multi-label dataset ; multi-label classifier ; label incompleteness ; multi-label applications ; human annotators	<task> <task> <task> <task> <method> <otherscientificterm> <material> <method> <otherscientificterm> <task> <otherscientificterm>	4 0 1	in this paper , we specifically examine the training of a <method_7> from data with incompletely assigned labels . this problem is fundamentally important in many <task_9> because it is almost impossible for <otherscientificterm_10> to assign a complete set of labels , although their judgments are reliable . in other words , a <material_6> usually has properties by which -lrb- 1 -rrb- assigned labels are definitely positive and -lrb- 2 -rrb- some labels are absent but are still considered positive . such a setting has been studied as a <task_0> in a <otherscientificterm_5> . we treat <task_1> as a <method_4> , which is an extension of <task_3> to the <task_2> . we derive the conditions that should be satisfied to cancel the negative effects of <otherscientificterm_8> . our experimentally obtained results demonstrate the effectiveness of these conditions .	7 11 -1 9 10 11 -1 6 11 -1 0 5 11 -1 1 4 12 11 -1 3 2 11 -1 8 11 -1
Conditional Vector Quantization for Voice Conversion .	constrained vector quantization ; hard clustering ; source and target data ; training speech data ; short-time spectral envelope ; voice conversion methods ; voice conversion ; spectral vectors ; vq approach ; cvq-based function	<method> <method> <material> <material> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm>	0 6 8 ; 9 0 6 ; 8 0 6	voice conversion methods have the objective of transforming speech spoken by a particular source speaker , so that it sounds as if spoken by a different target speaker . the majority of <method_5> is based on transforming the <otherscientificterm_4> of the source speaker , based on derived correspondences between the source and target vectors using <material_3> from both speakers . these correspondences are usually obtained by segmenting the <otherscientificterm_7> of one or both speakers into clusters , using soft -lrb- gmm-based -rrb- or <method_1> . here , we propose that <task_6> performance can be improved by taking advantage of the fact that often the relationship between the source and target vectors is one-to-many . in order to illustrate this , we propose that a <method_8> namely <method_0> , can be used for <task_6> . results indicate that indeed such a relationship between the <material_2> exists and can be exploited by following a <otherscientificterm_9> for <task_6> .	10 -1 5 4 3 10 -1 7 1 10 -1 6 10 -1 11 13 10 -1 8 0 12 10 -1
A multimodal learning interface for word acquisition .	user 's perspective video ; temporal correlations of data ; hypothesized lexical items ; natural language descriptions ; user-centric multisensory information ; non-speech contextual information ; multimodal learning algorithm ; natural interactions ; unsupervised mode ; continuous speech ; non-speech modalities ; multimodal interface ; object names ; word spotting ; head directions ; gaze positions ; hand movements ; em-based method ; acoustic signals ; modalities	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <material> <method> <material> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	8 0 11 ; 0 1 14 ; 14 6 10 ; 4 0 18 ; 0 6 10 ; 0 1 15 ; 9 0 6 ; 15 6 10 ; 10 0 4 ; 15 1 14 ; 14 1 16 ; 5 0 13 ; 10 0 18 ; 16 6 10	we present a <method_11> that learns words from <material_7> with users . the <method_11> can be trained in <method_8> in which users perform everyday tasks while providing <material_3> of their behaviors . we collect <material_18> in concert with <otherscientificterm_4> from <otherscientificterm_10> , such as <otherscientificterm_0> , <otherscientificterm_15> , <otherscientificterm_14> and <otherscientificterm_16> . a <method_6> is developed that firstly spots words from <material_9> and then associates action verbs and <otherscientificterm_12> with their grounded meanings . the central idea is to make use of <otherscientificterm_5> to facilitate <task_13> , and utilize <otherscientificterm_1> from different <otherscientificterm_19> to build <otherscientificterm_2> . from those items , an <method_17> selects correct word-meaning pairs . successful learning has been demonstrated in the experiment of the natural task of '' stapling papers '' .	11 7 20 -1 8 3 21 20 -1 18 4 10 0 15 14 16 22 23 24 25 26 28 29 30 31 33 34 20 -1 6 9 12 27 20 -1 5 13 1 19 2 32 20 -1 20 -1 17 20 -1
Neighborhood Aided Implicit Active Contours .	adaptively determined local influence domain ; synthetic and real images ; geometric and parametric snakes ; automatic local scale selection ; noisy and broken edges ; image/prior-driven evolution forces ; priori boundary information ; stable boundary detection ; geometric deformable model ; finite difference method ; regional inter-point constraints ; geometric contour point ; level set function ; partial differential equation ; neighborhood influence ; edge information ; image forces ; front evolution ; topological changes	<material> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 1 5 ; 8 0 2 ; 10 1 16 ; 16 1 6 ; 6 0 11 ; 14 0 8 ; 9 0 13	we have developed a <method_8> that employs <otherscientificterm_14> to achieve robust segmen-tation for <otherscientificterm_4> . the fundamental power of this <method_8> rests with the explicitly combination of <otherscientificterm_10> , <otherscientificterm_16> , and a <otherscientificterm_6> for each <otherscientificterm_11> within its <material_0> . this <method_8> thus naturally unifies the essences of the <otherscientificterm_2> through <method_3> , and exhibits their respective fundamental strengths of allowing <task_7> when the <otherscientificterm_15> is weak and possibly discontinuous , while maintaining the abilities to handle <otherscientificterm_18> during <otherscientificterm_17> . in particular , this paper presents an implementation of the <method_8> through local integration of the <method_12> and the <otherscientificterm_5> , where the resulting <otherscientificterm_13> is solved numerically using standard <method_9> . experimental results on <material_1> demonstrate its superior performance .	8 14 4 25 19 -1 10 16 6 11 0 22 23 24 19 -1 2 3 7 15 18 17 21 19 -1 12 20 26 19 -1 5 13 9 19 -1
Multivariate Relevance Vector Machines for Tracking .	tracking articulated human body motion ; full human body tracking ; learning based approach ; relevance vector machines ; probabilistic tracking framework ; 3d hand tracking ; pose estimation problem ; multivariate outputs ; pose ambiguity ; one-to-many mapping ; temporal information ; shape templates ; shape-context histograms ; hausdorff features ; image features ; state space ; clutter	<task> <task> <method> <method> <method> <task> <task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	14 0 15 ; 14 0 9 ; 2 0 6 ; 9 0 8 ; 9 0 15 ; 3 0 9 ; 5 1 1 ; 2 0 0 ; 3 0 15 ; 2 0 1 ; 10 3 4 ; 2 0 5	this paper presents a <method_2> to <task_0> from a single camera . in order to address the problem of <task_8> , a <method_9> from <otherscientificterm_14> to <otherscientificterm_15> is learned using a set of <method_3> , extended to handle <otherscientificterm_7> . the <otherscientificterm_14> are hausdorff matching scores obtained by matching different <otherscientificterm_11> to the image , where the multivariate <method_3> -lrb- mvrvm -rrb- select a sparse set of these <otherscientificterm_11> . we demonstrate that these <otherscientificterm_13> reduce the estimation error in <otherscientificterm_16> compared to <method_12> . the <method_2> is applied to the <task_6> from a single input frame , and is embedded within a <method_4> to include <otherscientificterm_10> . we apply the <method_2> to <task_5> and <task_1> .	2 0 25 17 -1 8 9 14 15 3 7 18 19 21 22 23 26 17 -1 11 17 -1 13 16 12 17 -1 6 20 28 17 -1 4 10 24 27 29 17 -1
A dereverberation algorithm for spherical microphone arrays using compressed sensing techniques .	compressed sensing technique ; spherical harmonic domain ; multiple-input/output inverse-filtering theorem ; room impulse responses ; multichannel dereverber-ation algorithm ; spherical microphone array ; reverber-ant environment ; computer simulation ; sparse recovery ; inverse filters ; mint	<method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method>	4 0 5 ; 7 0 4 ; 0 0 4 ; 8 0 4	in this paper , we present a novel <method_4> that enhances a target signal in a <otherscientificterm_6> . the proposed <method_4> is designed for a <otherscientificterm_5> and formulated in the <material_1> . the <method_4> employs <otherscientificterm_8> , a <method_0> , to estimate the position of the target signal and its early reflections . <otherscientificterm_3> are obtained according to the estimations and the <method_10> -lrb- the <method_2> -rrb- is used to calculate the <method_9> . the performance of the proposed <method_4> is evaluated using <method_7> and our results indicate the effectiveness of the proposed <method_4> .	4 6 11 -1 5 1 12 11 -1 8 0 3 14 15 11 -1 10 2 9 11 -1 7 13 11 -1
Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations .	parameter-space geometry of recurrent neural networks ; long-term dependency structure ; path-sgd optimization method ; relu rnns ; initialization schemes ; relu activations ; rnns ; path-sgd ; sgd	<method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method> <method>	7 4 6 ; 3 4 6	we investigate the <method_0> -lrb- <method_6> -rrb- , and develop an adaptation of <method_2> , attuned to this geometry , that can learn plain <method_6> with <otherscientificterm_5> . on several datasets that require capturing <otherscientificterm_1> , we show that <method_7> can significantly improve trainability of <method_3> compared to <method_6> trained with <method_8> , even with various recently suggested <method_4> .	0 6 2 5 9 -1 1 7 3 8 4 10 11 9 -1
Visual Motif Discovery via First-Person Vision .	people 's visual attention ; weighted covariance matrix ; normalized spectral clustering ; visual motif discovery ; commonality clustering method ; intra-video sparseness ; inter-video similarity ; visual motifs ; first-person videos ; wearable camera ; visual motifs ; accuracy	<otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <metric>	3 5 4 ; 1 0 2 ; 9 0 7 ; 6 1 5 ; 5 1 0 ; 11 5 4 ; 8 0 7	visual motifs are images of visual experiences that are significant and shared across many people , such as an image of an informative sign viewed by many people and that of a familiar social situation such as when interacting with a clerk at a store . the goal of this study is to discover <material_7> from a collection of <material_8> recorded by a <otherscientificterm_9> . to achieve this goal , we develop a <method_4> that leverages three important aspects : <otherscientificterm_6> , <otherscientificterm_5> , and <otherscientificterm_0> . the problem is posed as <method_2> , and is solved efficiently using a <method_1> . experimental results suggest the effectiveness of our <method_4> over several state-of-the-art methods in terms of both <metric_11> and efficiency of <task_3> .	12 -1 7 8 9 15 19 12 -1 4 6 5 0 16 17 12 -1 2 14 12 -1 1 13 18 12 -1
Utilizing online content as domain knowledge in a multi-domain dynamic dialogue system .	dialogue manager ; online sources ; dialogue systems ; web sites ; domain knowledge ; site structure ; multi-domain dialogue ; internet	<method> <material> <task> <material> <otherscientificterm> <otherscientificterm> <task> <material>	1 0 6	recent research in <task_2> has investigated the feasibility of relying on information extracted from the <material_7> as a source of content and <otherscientificterm_4> . however , this information needs to be processed and prepared into a form understandable by the <method_0> . the number of domains and <material_3> are often restricted to a finite number , with prior knowledge of the <otherscientificterm_5> itself usually required by the <method_0> . we present an architecture which demonstrates that <task_6> , relying on information extracted from <material_1> , is possible without the need for human intervention or knowledge of the <otherscientificterm_5> itself .	2 7 4 8 -1 0 8 -1 3 5 8 -1 6 1 9 8 -1
HMM adaptation and voice conversion for the synthesis of child speech : a comparison .	data-driven synthesis of child speech ; linguistic and prosodic knowledge ; linguistic or prosodic knowledge ; model adaptation techniques ; wave-form concatenation synthesiser ; statistical parametric synthesiser ; speech of adults ; voice conversion techniques ; natural speech ; hmm-based systems ; synthetic speech ; speaker characteristics	<task> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <method> <material> <method> <material> <otherscientificterm>	7 0 4 ; 1 0 3 ; 3 0 5 ; 1 0 5	this study compares two different methodologies for producing <task_0> from existing systems that have been trained on the <material_6> . on one hand , an existing <method_5> is transformed using <method_3> , informed by <otherscientificterm_1> , to the <otherscientificterm_11> of a child speaker . this is compared with the application of <method_7> to convert the output of an existing <method_4> with no explicit <otherscientificterm_2> . in a subjective evaluation of the similarity of <material_10> to <material_8> from the target speaker , the <method_9> evaluated are generally preferred , although <method_5> is at least in part due to the higher dimensional acoustic features supported by these techniques .	0 6 12 -1 5 3 1 11 14 15 16 12 -1 7 4 2 13 12 -1 10 8 9 12 -1
Data Integration for Classification Problems Employing Gaussian Process Priors .	large scale protein fold prediction problem ; variational & expectation propagation based methods ; ad hoc parameter tuning ; gaussian process priors ; heterogeneous data sets ; classification setting ; classifier combination ; covariance functions ; bayesian solution ; inference schemes	<task> <method> <method> <method> <material> <method> <method> <otherscientificterm> <method> <method>	2 1 6	by adopting <method_3> a fully <method_8> to the problem of integrating possibly <material_4> within a <method_5> is presented . approximate <method_9> employing <method_1> are developed and rigorously assessed . we demonstrate our approach to integrating multiple data sets on a <task_0> where we infer the optimal combinations of <otherscientificterm_7> and achieve state-of-the-art performance without resorting to any <method_2> and <method_6> .	3 8 4 5 10 -1 9 1 10 -1 0 7 2 6 11 10 -1
Modeling Human Motion Using Binary Latent Variables .	real-valued '' visible '' variables ; latent and visible variables ; binary latent variables ; human motion data ; non-linear generative model ; approximate learning procedure ; directed connections ; on-line inference ; undirected model ; motion sequences ; motion capture ; joint angles ; training	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm> <task>	8 0 4 ; 2 0 8 ; 4 0 3	we propose a <method_4> for <material_3> that uses an <method_8> with <otherscientificterm_2> and <otherscientificterm_0> that represent <otherscientificterm_11> . the <otherscientificterm_1> at each time step receive <otherscientificterm_6> from the visible variables at the last few time-steps . such an <method_4> makes <task_7> efficient and allows us to use a simple <method_5> . after <task_12> , the <method_4> finds a single set of parameters that simultaneously capture several different kinds of motion . we demonstrate the power of our <method_4> by synthesizing various <material_9> and by performing on-line filling in of data lost during <otherscientificterm_10> .	4 3 8 2 0 11 14 15 16 13 -1 1 6 13 -1 7 5 13 -1 12 13 -1 9 10 13 -1
AR model parameter estimation : from factor graphs to algorithms .	auto-regressive model ; parameter estimation algorithms ; factor graph ; ar coefficients ; summary propagation ; noise variance ; graphical-model viewpoint ; innovation variance	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 1 5 ; 3 1 7 ; 4 0 2 ; 6 0 0	the classic problem of estimating the parameters of an <method_0> is considered from a <otherscientificterm_6> . a number of practical <method_1> -- some of them well known , others apparently new -- are derived as '' <otherscientificterm_4> '' in a <method_2> . in particular , we demonstrate joint estimation of <otherscientificterm_3> , <otherscientificterm_7> , and <otherscientificterm_5> .	0 6 12 8 -1 1 4 2 11 8 -1 3 7 5 9 10 8 -1
Spatial Reasoning in Indeterminate Worlds .	relative locations of entities ; relative locations of symbols ; indeterminacy or partial knowledge ; primitive array functions ; model-based spatial reasoning ; nonmonotonic reasoning ; array map ; array representations ; worlds semantics ; symbolic arrays ; model-theoretic approach ; deduction ; world ; symbols	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 11 ; 8 0 4 ; 7 0 5 ; 3 0 7 ; 13 3 6	a possible <otherscientificterm_8> for <task_4> is presented . in this <otherscientificterm_8> , worlds are characterized by the alternative states that result from <otherscientificterm_2> . a <otherscientificterm_12> is represented as a set of <otherscientificterm_9> , where <otherscientificterm_13> in the <otherscientificterm_6> to entities in the <otherscientificterm_12> and the <otherscientificterm_1> correspond to the <otherscientificterm_0> . <otherscientificterm_11> is carried out using a <method_10> in which <method_7> are '' inspected '' using <otherscientificterm_3> . <method_5> using <method_7> is also discussed .	8 4 16 14 -1 2 14 -1 12 9 13 6 1 0 11 19 14 -1 10 7 3 5 15 18 14 -1 17 14 -1
A Multi-Pass Sieve for Name Normalization .	normalizing disorder names ; sieve based architecture ; deterministic normalization modules ; multi-pass sieve framework ; normalization task ; normalizing names ; biomedi-cal text ; coreference resolution ; characteristic features ; clinical notes ; accuracy	<task> <method> <method> <method> <task> <task> <material> <task> <otherscientificterm> <material> <metric>	1 0 7 ; 9 1 6 ; 1 0 4 ; 2 0 3	we propose a simple <method_3> that applies tiers of <method_2> one at a time from highest to lowest precision for the task of <task_5> . while a <method_1> has been shown effective in <task_7> , <method_1> has not yet been applied to the <task_4> . we find that even in this task , the <method_3> retains its <otherscientificterm_8> of being simple , and highly modular . in addition , <method_1> also proves robust when evaluated on two different kinds of data : <material_9> and <material_6> , by demonstrating high <metric_10> in <task_0> found in both datasets .	3 2 5 15 11 -1 1 7 4 12 14 11 -1 8 11 -1 9 6 10 0 13 11 -1
Inferring 3D Body Pose from Silhouettes Using Activity Manifold Learning .	view-based representations of activity manifolds ; spatial or temporal outliers ; 3d body pose space ; intrinsic body configuration ; 3d body pose ; visual input space ; body pose ; 3d pose ; manifold representation ; visual input ; view point ; central representations ; human silhouettes ; closed form ; mapping functions	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 1 2 ; 0 0 14 ; 13 0 6 ; 12 0 4	we aim to infer <otherscientificterm_4> directly from <otherscientificterm_12> . given a <otherscientificterm_9> -lrb- silhouette -rrb- , the objective is to recover the <otherscientificterm_3> , recover the <otherscientificterm_10> , reconstruct the input and detect any <otherscientificterm_1> . in order to recover <otherscientificterm_3> -lrb- pose -rrb- from the <otherscientificterm_9> -lrb- silhouette -rrb- , we explicitly learn <method_0> as well as learn <otherscientificterm_14> between such <method_11> and both the <otherscientificterm_5> and the <otherscientificterm_2> . the <otherscientificterm_6> can be recovered in a <otherscientificterm_13> in two steps by projecting the <otherscientificterm_9> to the learned representations of the activity manifold , i.e. , finding the point on the learned <method_8> corresponding to the <otherscientificterm_9> , followed by interpolating <otherscientificterm_7> .	4 12 19 15 -1 9 3 10 1 15 -1 0 14 11 5 2 16 17 15 -1 6 13 18 15 -1
Continuous Global Evidence-Based Bayesian Modality Fusion for Simultaneous Tracking of Multiple Objects .	probabilistic fusion of multiple visual cues ; real-time tracking of objects ; bayesian modality fusion network ; continuous domain variables ; computational complexity problems ; tracking multiple objects ; discrete spatial variables ; bayesian network ; visual data ; instantaneous inference ; discretisation ; modalities	<otherscientificterm> <task> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 7 ; 4 2 7 ; 3 0 2 ; 8 0 1 ; 10 1 4	robust , <task_1> from <material_8> requires <otherscientificterm_0> . previous approaches have either been ad hoc or relied on a <method_7> with <otherscientificterm_6> which suffers from <otherscientificterm_10> and <metric_4> . we present a new <method_2> that uses <otherscientificterm_3> . the <method_7> distinguishes between cues that are necessary or unnecessary for the object 's presence . computationally expensive and inexpensive <otherscientificterm_11> are also handled differently to min-imise cost . the <method_2> provides a formal , tractable and robust probabilistic <method_2> for simultaneously <task_5> . while <otherscientificterm_9> is exact , approximation is required for propagation over time .	1 8 0 16 12 -1 7 6 10 4 13 14 17 12 -1 2 3 15 12 -1 12 -1 11 12 -1 5 12 -1 9 12 -1
Recent advances in phonotactic language recognition using binary-decision trees .	nist language recognition evaluation task ; recursive bottom-up smoothing step ; flip-flop approximation algorithm ; tree adaptation step ; data sparseness issues ; binary decision trees ; algorithmic steps ; language recognition ; computational complexity	<task> <method> <method> <method> <task> <task> <method> <task> <metric>	4 1 8 ; 1 0 7 ; 6 0 4 ; 2 0 7 ; 2 0 0 ; 5 0 7 ; 1 1 2	binary decision trees are an effective model structure in <task_7> . this paper presents several related <method_6> to address <task_4> and <metric_8> . in particular , a <method_3> , a <method_1> , and two variants of the <method_2> are introduced to <task_7> and studied in the context of the <task_0> .	7 15 9 -1 6 4 8 10 12 9 -1 3 1 2 0 5 11 13 14 16 9 -1
On The Fundamental Performance For Fingerprint Matching .	nist-4 fingerprint database ; error rates ; person authentication ; fingerprint matching ; formal framework ; ridge counts ; fingerprints	<material> <metric> <task> <task> <method> <otherscientificterm> <material>	1 5 3 ; 4 0 3 ; 6 0 2	fingerprints have long been used for <task_2> . however , there is not enough scientific research to explain the probability that two fingerprints , which are impressions of different fingers , may be taken as the same one . in this paper , we propose a <method_4> to estimate the fundamental algorithm independent error rate of <task_3> . unlike a previous work , which assumes that there is no overlap between any two minutiae uncertainty areas and only measures minutiae 's positions and orientations , in our <method_4> , we do not make this assumption and measure the relations , i.e. <otherscientificterm_5> , between different minutiae as well as minutiae 's positions and orientations . the <metric_1> of <task_3> obtained by our <method_4> are significantly lower than that of previously published research . results are shown using <material_0> . these results contribute towards making <task_3> a science and settling the legal challenges to fingerprints .	2 10 7 -1 7 -1 4 3 9 7 -1 7 -1 5 8 7 -1 1 7 -1 0 7 -1
Minimizing Global Interconnect in DSP Systems using Bypassing .	integer-linear programming formulation ; user specified interconnect requirements ; compilation and architectural techniques ; deep submicron technologies ; cplex ilp solver ; routing congestion ; throughput requirements ; ic designs ; bypass units ; bypassing problem ; trimaran architecture ; compilation tools ; interconnect requirements ; complexity	<method> <otherscientificterm> <method> <method> <method> <task> <otherscientificterm> <method> <method> <task> <method> <method> <otherscientificterm> <metric>	10 1 11 ; 10 1 4 ; 11 1 4 ; 2 0 12 ; 8 0 5	there is a wide consensus that performance and power consumption of <method_7> in <method_3> is mainly dictated by <otherscientificterm_12> . our goal is demonstrate how <method_2> can be used to minimize and balance <otherscientificterm_12> . specifically , we target the use of <method_8> to reduce <task_5> and eliminate long interconnections while essentially preserving or even improving the <otherscientificterm_6> . we formulate the <task_9> , establish its <metric_13> and develop an efficient <method_0> . in addition to satisfying <otherscientificterm_1> , we simultaneously optimize the number of operations and , therefore runtime of the targeted application.the approach is prototyped and evaluated using a platform consisting of the <method_10> and <method_11> and the <method_4> .	7 3 12 14 -1 2 18 14 -1 8 5 6 19 14 -1 9 13 0 14 -1 1 15 16 17 14 -1
Automatic Generation of Social Tags for Music Recommendation .	web2 .0 '' recommender systems ; social tags ; boosted classifiers ; tag space ; user-generated keywords ; audio features ; social tags ; use-dependent terms ; mp3 files ; cold-start problem ; recom-mender system ; baseline tags ; social recommender ; similarities ; playlists ; jogging ; web ; autotags	<method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material>	16 0 6 ; 17 0 3	social tags are <otherscientificterm_4> associated with some resource on the <material_16> . in the case of music , <otherscientificterm_6> have become an important component of '' <method_0> , allowing users to generate <otherscientificterm_14> based on <otherscientificterm_7> such as chill or <otherscientificterm_15> that have been applied to particular songs . in this paper , we propose a method for predicting these <otherscientificterm_6> directly from <material_8> . using a set of <method_2> , we map <otherscientificterm_5> onto <otherscientificterm_6> collected from the <material_16> . the resulting automatic tags -lrb- or autotags -rrb- furnish information about music that is otherwise untagged or poorly tagged , allowing for insertion of previously unheard music into a <otherscientificterm_12> . this avoids the '' <task_9> '' common in such systems . <material_17> can also be used to smooth the <otherscientificterm_3> from which <otherscientificterm_13> and recommendations are made by providing a set of comparable <otherscientificterm_11> for all tracks in a <method_10> .	4 16 18 -1 6 0 14 7 15 18 -1 8 18 -1 2 5 19 18 -1 18 -1 12 18 -1 9 17 20 18 -1
Mixed physical modeling techniques applied to speech production .	finite difference time-domain schemes ; wave digital filters ; discrete-time modeling of speech production ; digital waveguides ; articulatory type of speech production ; kelly-lochbaum transmission-line model ; mixed physical modeling ; real-time synthesizers ; generalized methodology ; computer music ; speech synthesis ; vocal tract ; speech production	<method> <method> <task> <method> <task> <method> <method> <method> <method> <material> <task> <otherscientificterm> <task>	0 1 1 ; 7 0 4 ; 12 1 10 ; 6 0 12 ; 3 1 0	the <method_5> of the <otherscientificterm_11> started the <task_2> . more recently similar techniques have been developed in <material_9> towards a more <method_8> . in this paper we will study the application of <method_6> to <task_12> and <task_10> . these approaches are <method_3> , <method_0> , and <method_1> . the equivalence and interconnectivity of these schemes is shown and flexible <method_7> for <task_4> are demonstrated .	5 11 2 13 -1 9 8 13 -1 6 12 10 16 17 13 -1 3 0 1 14 18 13 -1 7 4 15 13 -1
Can back-ends be more robust than front-ends ? Investigation over the Aurora-2 database .	convolutive noise compensation ; relative word error rate reduction ; noise robust speech recognition ; enhanced channel estimation procedure ; n-pass decoding algorithm ; speech acoustic models ; texas instruments ; recognition features ; back-end solution ; aurora-2 database ; joint additive ; model parameters	<method> <metric> <task> <method> <method> <method> <method> <method> <method> <material> <method> <otherscientificterm>	1 5 8 ; 6 0 2 ; 9 5 8 ; 8 0 2 ; 10 3 8 ; 6 0 8 ; 10 1 0 ; 0 3 8 ; 0 0 5	we present a <method_8> developed at <method_6> for <task_2> . the <method_8> consists of three techniques : 1 -rrb- a <method_10> and <method_0> which adapts <method_5> , 2 -rrb- an <method_3> which extends jac performance towards lower snr ranges , and 3 -rrb- an <method_4> . the performance of the proposed <method_8> is evaluated on the <material_9> . with 20 % less <otherscientificterm_11> and without the need for second order derivative of the <method_7> , the performance of the proposed <method_8> is 91.86 % , which outperforms that of the etsi advanced front-end standard -lrb- 88.19 % -rrb- by more than 30 % <metric_1> .	8 6 2 14 16 18 12 -1 10 0 5 3 4 17 19 20 21 12 -1 9 15 12 -1 11 7 13 12 -1
Simultaneous seismic compression and denoising using a lapped transform coder .	noise-free seismic data model ; naturally noisy seismic data ; initial ambient noise ; embedded zerotree coding ; lapped transform coder ; seismic field data ; seismic signals ; natural images ; seismic information ; denoising tool ; compression ratios ; seismic data ; compression ; wavelets	<method> <material> <otherscientificterm> <method> <method> <material> <material> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	3 0 4	compression and denoising are two of the most successful applications of <otherscientificterm_13> to signals and <material_7> . both techniques have also been successfully applied to <material_6> , but compression is not widely accepted yet , since it is often believed to harm <otherscientificterm_8> . trying to look at compression and denoising in another direction , the present work stresses on the idea that they could be viewed as two sides of the same coin . as a result , in the case of <material_1> , compression could be seen as a <method_9> , instead of a mere noise source . we subtantiate this statement on a <method_0> and actual <material_5> . we show that , depending on the amout of <otherscientificterm_2> in the data , a <method_4> with <method_3> may be able to effectively denoise <material_11> , over a wide range of <otherscientificterm_10> .	13 7 14 -1 6 8 14 -1 14 -1 1 9 14 -1 14 -1 0 5 15 14 -1
Queries as a Source of Lexicalized Commonsense Knowledge .	extraction of attributes of instances and classes ; web search queries ; open-domain commonsense knowledge ; open-domain information extraction ; web documents ; lexicalized assertions ; factual knowledge ; open-domain classes	<task> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 2 2 ; 7 2 5 ; 1 0 2	the role of <task_1> has been demonstrated in the <task_0> , or of sets of related instances and their class labels . this paper explores the acquisition of <otherscientificterm_2> , usually available as <otherscientificterm_6> , from <task_1> . similarly to previous work in <task_3> , knowledge extracted from text-in this case , from queries-takes the form of <otherscientificterm_5> associated with <otherscientificterm_7> . experimental results indicate that facts extracted from queries complement , and have competitive accuracy levels relative to , facts extracted from <material_4> by previous methods .	1 0 8 -1 2 6 9 11 8 -1 3 5 7 10 8 -1 4 8 -1
Heterogeneous Continuous Dynamic Bayesian Networks with Flexible Structure and Inter-Time Segment Information Sharing .	classical dynamic bayesian networks ; inter-time segment information sharing ; gene expression time series ; homogeneous markov assumption ; time-invariant network structure ; synthetic data ; temporal processes ; regularization scheme ; data discretization ; homogeneity assumption ; drosophila melanogaster ; heterogeneous dbns ; overfitting ; flexibility ; heterogeneity ; over-flexibility	<method> <otherscientificterm> <task> <otherscientificterm> <method> <material> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <otherscientificterm>	1 0 7 ; 14 2 6 ; 3 0 0 ; 15 1 12	classical dynamic bayesian networks -lrb- dbns -rrb- are based on the <otherscientificterm_3> and can not deal with <otherscientificterm_14> and non-stationarity in <otherscientificterm_6> . various approaches to relax the <otherscientificterm_9> have recently been proposed . the present paper aims to improve the shortcomings of three recent versions of <method_11> along the following lines : -lrb- i -rrb- avoiding the need for <task_8> , -lrb- ii -rrb- increasing the <metric_13> over a <method_4> , -lrb- iii -rrb- avoiding <otherscientificterm_15> and <method_12> by introducing a <method_7> based in <otherscientificterm_1> . the improved method is evaluated on <material_5> and compared with alternative published methods on <task_2> from <otherscientificterm_10> .	3 14 6 18 19 16 -1 9 16 -1 11 8 13 4 15 12 7 1 17 20 16 -1 5 16 -1
Trade-off evaluation for speech enhancement algorithms with respect to the a priori SNR estimation .	decision-directed approach ; modified sigmoid gain function ; noisy speech spectrum ; speech transient distortion ; log-spectral amplitude estimator ; priori snr estimator ; objective evaluation metric ; modified dd approach ; trade-off evaluation ; noise reduction ; speech enhancement ; speech distortion ; gain function ; wiener filter ; snr estimate ; musical noise ; smoothing	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <method> <metric> <task> <task> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task>	4 1 13 ; 5 0 3 ; 15 1 9 ; 8 5 5 ; 5 0 10 ; 9 1 11	in this paper , a modified a <method_5> is proposed for <task_10> . the well-known <method_0> is modified by matching each <otherscientificterm_12> with the <otherscientificterm_2> at current frame rather than the previous one . the proposed <method_5> eliminates the <otherscientificterm_3> and reduces the impact from the choice of the <otherscientificterm_12> towards the level of <task_16> in the <task_14> . an <metric_6> is employed to measure the trade-off between <otherscientificterm_15> , <task_9> and <otherscientificterm_11> . performance is evaluated and compared between a <otherscientificterm_1> , the state-of-the-art <method_4> and the <method_13> . simulation results show that the <method_7> performs better in terms of the <metric_8> .	5 10 22 17 -1 0 12 2 17 -1 3 16 14 19 17 -1 6 15 9 11 20 23 17 -1 1 4 13 18 17 -1 7 21 17 -1
A mutual information based approach for evaluating the quality of clustering .	yeast cell cycle gene expression data ; gaussian kernel density estimator ; normalized mutual information criterion ; histogram-based modeling method ; clustering of genes ; mutual information criterion ; synthetic data ; cluster size ; clustering ; cluster ; cluster-centroids	<material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <method>	3 0 2 ; 5 0 4 ; 3 0 8 ; 1 0 2	in this paper , a new method for evaluating the quality of <method_4> is proposed based on <otherscientificterm_5> . instead of using the conventional <method_3> to assess <task_8> performance , we derive a <otherscientificterm_2> utilizing the <method_1> . in the computation of the <otherscientificterm_5> , we propose to use only <method_10> instead of involving all the members , which offers a huge computational savings . the proposed algorithm not only considers the <otherscientificterm_7> but also takes into consideration the homogeneity within a <otherscientificterm_9> . one major advantage of the proposed algorithm is that , it is capable of estimating an appropriate number of clusters . extensive experimentation has been carried out on some <material_6> as well as the most widely used <material_0> . under various <task_8> conditions it is found that the proposed method provides an excellent performance in terms of measuring the quality of <otherscientificterm_9> and identifying the true number of <otherscientificterm_9> .	4 5 13 11 -1 3 8 2 1 12 14 15 11 -1 10 11 -1 7 9 11 -1 11 -1 11 -1 6 0 11 -1
Instace-Based AMN Classification for Improved Object Recognition in 2D and 3D Laser Range Data .	2d and 3d laser range data ; associative markov networks ; nearest-neighbor classifier ; recorded indoor scenes ; instance-based feature extraction ; collective classification method ; nn classifier ; linear hyper-planes ; amn approach ; classification rate ; feature vectors ; nn	<material> <method> <method> <material> <method> <method> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <method>	2 1 11 ; 7 0 10 ; 1 0 5	in this paper , we present an algorithm to identify different types of objects from <material_0> . our method is a combination of an <method_4> similar to the <method_2> and a <method_5> that utilizes <method_1> . compared to previous approaches , we transform the <otherscientificterm_10> so that <otherscientificterm_10> are better separable by <otherscientificterm_7> , which are learned by the <method_1> . we present results of extensive experiments in which we evaluate the performance of our algorithm on several <material_3> and compare it to the standard <method_8> as well as the <method_6> . the <metric_9> obtained with our algorithm substantially exceeds those of the <method_2> and the <method_11> .	0 12 -1 4 2 5 1 15 12 -1 10 7 14 12 -1 3 8 6 12 -1 9 13 12 -1
Audio transients modeling by damped & delayed sinusoids -LRB- DDS -RRB- .	mcaulay & quatieri sinusoidal models ; modeling strong audio transients ; high resolution method ; delay parameter ; model parameters ; sub-band analysis ; damping factor ; pre-echo effects ; castanets onsets ; parametric model	<method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method>	0 0 9 ; 6 1 3 ; 5 0 2	in this paper , we present a novel <method_9> based on an important evolution of <method_0> -lsb- 5 -rsb- . this <method_9> takes into account a <method_6> as well as a <otherscientificterm_3> which makes <method_9> more efficient for <task_1> such as <otherscientificterm_8> without <otherscientificterm_7> 1 . we also develop an original algorithm to estimate the <otherscientificterm_4> by means of a <method_2> followed by a <method_5> .	9 0 11 10 -1 6 3 1 8 7 12 10 -1 4 2 5 13 10 -1
Unsupervised Semantic Intent Discovery from Call Log Acoustics .	automatic voice response system ; corporate voice-dialer application ; unforeseen user intents ; estimated semantic intents ; unforeseen semantic intents ; semantic error rate ; language models ; unsupervised manner ; manual transcriptions ; logged calls ; cluster	<method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <material> <material> <otherscientificterm>	8 0 4 ; 7 0 6	unforeseen user intents can account for a significant portion of unsuccessful calls in an <method_0> . discovering these <otherscientificterm_4> usually requires expensive <material_8> . we propose a method to <otherscientificterm_10> the acous-tics from <material_9> by their <otherscientificterm_3> . this is achieved through training a mixture of <method_6> in an <method_7> . each <otherscientificterm_10> is presented to the application developer with a suggested language model to cover the semantic intent of the data in that <otherscientificterm_10> . the application developer validates the <otherscientificterm_10> and its suggested language model , and then updates the application . a quantative evaluation on a <task_1> shows that updating the application in this manner yields a relative 13.4 % reduction in <metric_5> .	0 11 -1 4 8 12 11 -1 10 9 3 11 -1 6 7 13 11 -1 11 -1 11 -1 1 11 -1
Surface Reconstruction by Propagating 3D Stereo Data in Multiple 2D Images .	3d stereo data ; local surface patch ; 2d calibrated images ; density insufficiency ; surface patch ; local graph-cut ; constrained optimization ; stereo data ; stereo points ; surface reconstruction ; best-first strategy ; accuracy	<material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <task> <method> <metric>	0 1 2 ; 6 0 4	we present a novel approach to <task_9> from multiple images . the central idea is to explore the integration of both <material_0> and <material_2> . this is motivated by the fact that only robust and accurate feature points that survived the geometry scrutiny of multiple images are reconstructed in space . the <otherscientificterm_3> and the inevitable holes in the <material_7> should be filled in by using information from multiple images . the idea is therefore to first construct small surface patches from <otherscientificterm_8> , then to progressively propagate only reliable patches in their neighborhood from images into the whole surface using a <method_10> . the problem reduces to searching for an optimal <otherscientificterm_1> going through a given set of <otherscientificterm_8> from images . this <method_6> for a <otherscientificterm_4> could be handled by a <method_5> that we develop . real experiments demonstrate the usability and <metric_11> of the approach .	9 12 -1 0 2 13 12 -1 12 -1 3 7 12 -1 8 12 -1 10 12 -1 1 14 12 -1 6 4 5 12 -1
Weakly trained dual features extraction based detector for frontal face detection .	local binary patterns features ; lienhart frontal face detector ; frontal face detector ; multi-detections merging algorithm ; haar-like features ; non-face image ; face/non-face dataset ; real-life sequence ; joint decision ; clustering method ; features ; robustness	<method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <method> <otherscientificterm> <metric>	11 5 2 ; 6 0 2 ; 8 0 2 ; 9 0 3 ; 10 2 2	this paper investigates the inconvenience of using huge number of <otherscientificterm_10> , enormous training dataset and lengthy training session to achieve a good performance <method_2> . the proposed <method_2> is based on a novel idea which proposes using <otherscientificterm_8> from two parallel different <otherscientificterm_10> trained <method_2> , one <method_2> is trained with <method_0> and the other with <otherscientificterm_4> . both <method_2> are trained with few <otherscientificterm_10> using not a huge <material_6> and within relatively short period of time . hence , both <method_2> agree on the face image but seldom agree on the <otherscientificterm_5> . the result is significantly improved using a <method_3> using simple <method_9> . the <metric_11> of the <method_2> is examined once using a <material_6> and compared to <method_1> , and secondly using a <material_7> .	10 2 12 -1 8 0 4 15 12 -1 6 17 12 -1 5 12 -1 16 12 -1 3 9 13 14 12 -1
Aggregating Optimistic Planning Trees for Solving Markov Decision Processes .	random realization of the stochastic environment ; safe '' optimistic planning strategy ; forest of planning trees ; markov decision processes ; transition distributions ; online planning ; uniform exploration ; finite-sample analysis ; randomized simulator ; budget constraint ; safety principle ; safety ; tree	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <method> <metric> <otherscientificterm>	5 3 3 ; 8 0 3 ; 9 0 8 ; 8 0 5	this paper addresses the problem of <task_5> in <method_3> using a <method_8> , under a <otherscientificterm_9> . we propose a new algorithm which is based on the construction of a <otherscientificterm_2> , where each <otherscientificterm_12> corresponds to a <otherscientificterm_0> . the <otherscientificterm_2> are constructed using a '' <method_1> combining the optimistic principle -lrb- in order to explore the most promising part of the search space first -rrb- with a <method_10> -lrb- which guarantees a certain amount of <method_6> -rrb- . in the decision-making step of the algorithm , the individual <otherscientificterm_2> are aggregated and an immediate action is recommended . we provide a <method_7> and discuss the trade-off between the principles of optimism and <metric_11> . we also report numerical results on a benchmark problem . our algorithm performs as well as state-of-the-art optimistic planning algorithms , and better than a related algorithm which additionally assumes the knowledge of all <otherscientificterm_4> .	5 3 8 9 14 15 16 17 13 -1 2 12 0 13 -1 1 10 6 13 -1 13 -1 13 -1 7 11 13 -1 13 -1
Spice it up ? Mining Refinements to Online Instructions from User Generated Content .	predicting refinement segments ; user-proposed refinements ; review level ; recipe domain ; predicting refinements ; subjective evaluation ; generative model ; instruction reviews ; unsupervised setting ; web sites	<task> <otherscientificterm> <otherscientificterm> <material> <task> <method> <method> <otherscientificterm> <method> <material>	6 0 1 ; 6 0 7	there are a growing number of popular <material_9> where users submit and review instructions for completing tasks as varied as building a table and baking a pie . in addition to providing their <method_5> , reviewers often provide actionable refinements . these refinements clarify , correct , improve , or provide alternatives to the original instructions . however , identifying and reading all relevant reviews is a daunting task for a user . in this paper , we propose a <method_6> that jointly identifies <otherscientificterm_1> in <otherscientificterm_7> at multiple granularities , and aligns <otherscientificterm_1> to the appropriate steps in the original instructions . labeled data is not readily available for these tasks , so we focus on the <method_8> . in experiments in the <material_3> , our <method_6> provides 90.1 % f 1 for <task_4> at the <otherscientificterm_2> , and 77.0 % f 1 for <task_0> within reviews .	9 10 -1 5 10 -1 10 -1 10 -1 6 1 7 11 12 10 -1 10 -1 8 10 -1
A Probabilistic Framework for Space Carving .	space carving -lsb- 9 -rsb- ; real and synthetic data ; global threshold parameter ; voxel-based thick texture ; space carving algorithm ; probabilistic framework ; dominant planes ; representation ; voxel	<task> <material> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	1 0 5	this paper introduces a new <method_5> for <task_0> . in this <method_5> each <otherscientificterm_8> is assigned a probability , which is computed by comparing the likelihoods for the <otherscientificterm_8> existing and not existing . this new <method_5> avoids many of the difficulties associated with the original <method_4> . specifically , it does not need a <otherscientificterm_2> , and it guarantees that no holes will be carved in the <method_4> . this paper also proposes that a <otherscientificterm_3> is a realistic and efficient <method_7> for scenes which contain <otherscientificterm_6> . the <method_5> is tested using both <material_1> , and both qualitative and quantitative results are presented .	5 0 9 -1 8 9 -1 4 9 -1 2 9 -1 3 7 6 9 -1 1 10 9 -1
Efficient Consequence Finding .	model-based and fault-tree diagnosis ; zero-suppressed binary decision diagrams ; restricted target languages ; polynomially-bounded knowledge compilation ; kernel resolution ; zbdd-based implementation ; zbdd implementation ; consequence-finding algorithms ; abduction ; consequence-finding	<task> <method> <otherscientificterm> <task> <task> <method> <method> <method> <task> <method>	0 1 3 ; 8 1 0 ; 4 0 7	we present an extensive experimental study of <method_7> based on <task_4> , using both a trie-based and a novel <method_5> , which uses <method_1> to concisely store and process very large clause sets . our study considers both the full prime implicate task and applications of <method_9> for <otherscientificterm_2> in <task_8> , <task_0> , and <task_3> . we show that the <method_6> can push <method_9> to a new limit , solving problems which generate over 1/2 1/4 1/4 clauses .	7 4 5 1 13 10 -1 9 2 8 0 3 11 12 10 -1 6 10 -1
Ultrasonic Signal Processing For Archaeological Ceramic Restoration .	ultrasonic signature of the material properties ; wave propagation velocity ; archaeological ceramic pieces ; linear discriminant analysis ; centroid frequency evolution ; ultrasound propagation velocity ; archaeological period classification ; ultrasonic signal processing ; signal parameters ; ultrasonic signature ; consolidation products ; dominant frequency ; material porosity ; ultrasonic signals ; ceramic fragments ; signal attenuation ; parameters ; pieces	<otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 6 8 ; 4 0 9 ; 1 6 8 ; 3 0 16 ; 11 1 15 ; 15 6 8 ; 1 1 11	this paper presents an application of <task_7> to find parameters related with physical properties of <material_2> and <method_10> used in their restoration . <otherscientificterm_17> consisted of <otherscientificterm_14> from bronze , iberian , roman and middle ages . <otherscientificterm_13> measured from the pieces were processed to derive an <otherscientificterm_0> . <otherscientificterm_8> , such as , <otherscientificterm_1> , <otherscientificterm_11> , and <otherscientificterm_15> , were estimated . <otherscientificterm_16> were processed by <method_3> obtaining a good fitting for <task_6> . <otherscientificterm_9> based on <otherscientificterm_4> was dissimilar for different <method_10> . <otherscientificterm_5> and others parameters were related with the <otherscientificterm_12> .	7 2 10 17 18 -1 14 13 18 -1 0 8 18 -1 1 11 15 16 19 21 23 24 25 18 -1 3 6 9 22 18 -1 4 5 20 18 -1 12 18 -1
Hyper-class augmented and regularized deep learning for fine-grained image classification .	deep convolutional neural networks ; fine-grained image classification ; large-scale generic object recognition ; fine-grained labeled data ; generic object recognition ; fine-grained recognition model ; large-scale external dataset ; small-scale target data ; large-scale car dataset ; small training data ; hyper-class recognition model ; small-scale fine-grained datasets ; image search engines ; hyper-class-labeled images ; fine-grained data ; fine-tuning strategy ; inter-class variance ; domain expertise ; learning model ; image recognition ; external sources ; classification task ; annotated hyper-classes ; multi-task learning ; systematic framework ; regularization	<method> <task> <task> <material> <task> <method> <material> <material> <material> <material> <method> <material> <method> <material> <material> <method> <otherscientificterm> <otherscientificterm> <method> <task> <material> <task> <otherscientificterm> <task> <method> <method>	3 0 4 ; 8 5 24 ; 7 0 21 ; 11 5 24 ; 25 0 18 ; 5 0 18 ; 10 0 18 ; 13 0 23 ; 5 1 10	deep convolutional neural networks -lrb- cnn -rrb- have seen tremendous success in <task_2> . in comparison with <task_4> , <task_1> is much more challenging because -lrb- i -rrb- <material_3> is much more expensive to acquire -lrb- usually requiring <otherscientificterm_17> -rrb- ; -lrb- ii -rrb- there exists large intra-class and small <otherscientificterm_16> . most recent work exploiting deep cnn for <task_19> with <material_9> adopts a simple strategy : pre-train a deep cnn on a <material_6> -lrb- e.g. , imagenet -rrb- and fine-tune on the <material_7> to fit the specific <task_21> . in this paper , beyond the <method_15> , we propose a <method_24> of learning a deep cnn that addresses the challenges from two new perspectives : -lrb- i -rrb- identifying easily <otherscientificterm_22> inherent in the <material_14> and acquiring a large number of <material_13> from readily available <material_20> -lrb- e.g. , <method_12> -rrb- , and formulating the problem into <task_23> ; -lrb- ii -rrb- a novel <method_18> by exploiting a <method_25> between the <method_5> and the <method_10> . we demonstrate the success of the proposed <method_24> on two <material_11> -lrb- stanford dogs and stanford cars -rrb- and on a <material_8> that we collected .	2 26 -1 4 1 3 17 16 27 26 -1 19 9 6 7 21 29 26 -1 15 31 32 33 34 35 26 -1 24 22 14 13 20 12 23 18 25 5 10 28 30 26 -1
Increasing the mixture components of non-uniform HMM structures based on a variational Bayesian approach .	successive state splitting algorithm ; variational bayesian approach ; maximum likelihood criterion ; non-uniform , context-dependent hmm topologies ; contex-tual and temporal variations ; ml based methods ; over-fitting problem ; temporal structures ; hmm topologies ; speech recognition ; mixture components ; acoustic models ; hmms	<method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method>	11 0 9 ; 10 0 1 ; 1 0 1 ; 1 0 3 ; 0 0 4 ; 1 0 11 ; 1 0 10 ; 5 0 1 ; 1 0 0 ; 1 4 1 ; 1 0 9 ; 2 0 8	we propose using the <method_1> for automatically creating <otherscientificterm_3> . although the <method_2> is generally used to create <otherscientificterm_8> , <method_2> has an <task_6> . recently , to avoid this problem , the <method_1> has been applied to create <method_11> for <task_9> . we introduce the <method_1> to the <method_0> , which can create both <otherscientificterm_4> for <method_12> . experimental results show that the proposed <method_1> can automatically create a more efficient model than the original <method_1> . furthermore , we evaluated a <method_1> to increase the number of <method_10> by using the <method_1> and considering <otherscientificterm_7> . the <method_1> obtained the best performance with a smaller number of <method_10> in comparison with that obtained by using <method_5> .	1 3 17 13 -1 2 8 6 25 13 -1 11 9 14 19 24 13 -1 0 4 12 18 22 13 -1 23 13 -1 10 7 16 20 13 -1 15 21 13 -1
Multimodality gender estimation using Bayesian hierarchical model .	fingerprint based gender estimation ; fingerprint and face information ; fingerprint and face ; local image features ; bayesian hierarchical model ; gender estimation ; multimodal-ity model ; word representation ; human gender ; latent word ; decision level ; internal database	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	9 0 4 ; 7 0 6 ; 9 0 7	we propose to estimate <otherscientificterm_8> from corresponding <otherscientificterm_1> with the <method_4> . different from previous works on <task_0> with specially designed features , our method extends to use general <otherscientificterm_3> . furthermore , a novel <method_7> called <otherscientificterm_9> is designed to work with the <method_4> . the <method_7> is embedded to our <method_6> , within which the information from <otherscientificterm_2> is fused at the <otherscientificterm_10> for <task_5> . experiments on our <material_11> show the promising performance .	8 1 4 12 -1 0 3 12 -1 7 9 13 15 12 -1 6 2 10 5 14 12 -1 11 12 -1
Effects of pitch accent type on interpreting information status in synthetic speech .	intonational signalling of information status ; speech with contextually inappropriate intonation ; signalling of information status ; unit selection synthesis ; unit selection synthesis ; pitch accent ; information status ; intonational cues ; dialogue systems ; pitch accents ; synthetic speech ; eye-tracking paradigm ; deaccentuation ; intonation	<task> <material> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	0 0 3	unit selection synthesis has made it possible to produce speech with high quality . however , because it allows little control over <otherscientificterm_13> , it may produce <material_1> . in the <task_2> , <otherscientificterm_13> , in particular , choice of <otherscientificterm_5> , has been taken into account in a number of <method_8> . previous research shows that this can improve the perceived intonational appropriateness of <material_10> . using an <method_11> , this study investigates how <otherscientificterm_9> h * l and l * h and <otherscientificterm_12> affect the interpretation of <otherscientificterm_6> in <material_10> in english . it was found that h * l biases listeners ' interpretation to new information but l * h , like <otherscientificterm_12> , biases listeners ' interpretation to given information . these results indicate that listeners can and do make use of <otherscientificterm_7> in the interpretation of <otherscientificterm_6> in <material_10> and lend strong support to the integration of <task_0> into <method_3> .	14 -1 13 1 14 -1 2 5 8 14 -1 10 14 -1 11 9 12 6 14 -1 14 -1 15 14 -1
Extraction of Tree Adjoining Grammars from a Treebank for Korean .	feature-based lexicalized grammars ; well-formed morphological analysis ; korean sejong treebank ; full-scale syntactic tags ; syntactic features ; tree schemata ; sejong treebank ; lexicalized grammars ; tag grammars ; treebank	<method> <method> <material> <otherscientificterm> <otherscientificterm> <method> <material> <method> <method> <material>	9 0 7 ; 3 0 4 ; 7 0 5 ; 7 0 7 ; 2 0 0 ; 1 0 4 ; 3 1 1 ; 8 1 5 ; 7 1 0	we present the implementation of a system which extracts not only <method_7> but also <method_0> from <material_2> . we report on some practical experiments where we extract <method_8> and <method_5> . above all , <otherscientificterm_3> and <method_1> in <material_6> allow us to extract <otherscientificterm_4> . in addition , we modify <material_9> for extracting <method_7> and convert <method_7> into <method_5> to resolve limited lexical coverage problem of extracted <method_7> .	7 0 2 15 19 10 -1 8 5 18 10 -1 3 1 6 4 12 16 17 10 -1 9 11 13 14 10 -1
Non-parametric Similarity Measures for Unsupervised Texture Segmentation and Image Retrieval .	multi -- scale gabor filter bank ; non -- parametric statistical tests ; real -- word images ; texture based image retrieval ; parametric statistical tests ; unsuper-vised texture segmentation ; coefficients of images ; homogeneity measures ; micro	<material> <otherscientificterm> <material> <task> <method> <task> <otherscientificterm> <metric> <otherscientificterm>	3 1 5 ; 4 0 3 ; 4 0 5 ; 4 0 6 ; 0 0 6	in this paper we propose and examine <otherscientificterm_1> to define similarity and <metric_7> for textures . the statistical tests are applied to the <otherscientificterm_6> filtered by a <material_0> . we will demonstrate that these <method_4> are useful for both , <task_3> and for <task_5> , and hence offer an unified approach to these closely related tasks . we present results on brodatz -- like <otherscientificterm_8> -- textures and a collection of <material_2> .	1 7 9 -1 6 0 13 14 9 -1 4 3 5 10 11 12 9 -1 8 2 9 -1
Filter-and-sum beamformer with adjustable filter characteristics .	multi-dimensional extension of well-known far-row structure ; polynomial beamforming filter design ; interpolation of 1-d signals ; polynomial fir filter ; fractional delay filtering ; beamforming filter characteristics ; polynomial filter structure ; beamforming filter characteristic ; dynamic beam steering ; 20-tap delay lines ; control variable ; optimization method ; linear array ; omni-directional microphones ; filter-and-sum beamforming	<otherscientificterm> <task> <task> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <task>	6 0 1 ; 11 0 1 ; 14 0 1 ; 4 1 2 ; 9 2 3 ; 6 0 14 ; 10 0 8 ; 13 1 3	in this paper we introduce a <method_6> for <task_14> applied to <task_1> . the structure is a <otherscientificterm_0> , which has mainly been used for <task_4> and <task_2> . the proposed <method_6> enables an easy , smooth , and efficient control of <otherscientificterm_7> by adjusting only a single <otherscientificterm_10> e.g. for <method_8> . the <method_11> for <task_1> is presented and illustrated with simulations of <otherscientificterm_5> . the design example is given for a <method_12> of four <otherscientificterm_13> and a <method_3> with <otherscientificterm_9> .	6 14 1 16 18 21 15 -1 0 4 2 19 15 -1 7 10 8 22 15 -1 11 5 17 15 -1 12 13 3 9 20 23 15 -1
Voting Almost Maximizes Social Welfare Despite Limited Communication .	low communication costs ; full utility function ; cooperative multiagent systems ; voting rule ; communication burden ; voting rules ; social welfare ; randomized embeddings ; distortion ; veto ; communication ; voting ; approval	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm>	12 6 5 ; 7 0 8 ; 11 0 2 ; 0 2 5 ; 12 1 9 ; 9 6 5	in <method_2> an alternative that maximizes the <otherscientificterm_6> -- the sum of utilities -- can only be selected if each agent reports its <otherscientificterm_1> . this may be infeasible in environments where <task_10> is restricted . employing a <otherscientificterm_3> to choose an alternative greatly reduces the <otherscientificterm_4> , but leads to a possible gap between the <otherscientificterm_6> of the optimal alternative and the <otherscientificterm_6> of the one that is ultimately elected . procaccia and rosenschein -lrb- 2006 -rrb- have introduced the concept of <otherscientificterm_8> to quantify this gap . in this paper , we present the notion of embeddings into <otherscientificterm_5> : functions that receive an agent 's utility function and return the agent 's vote . we establish that very low <otherscientificterm_8> can be obtained using <otherscientificterm_7> , especially when the number of agents is large compared to the number of alternatives . we investigate our ideas in the context of three prominent <otherscientificterm_5> with <otherscientificterm_0> : plurality , <otherscientificterm_12> , and <otherscientificterm_9> . our results arguably provide a compelling reason for employing <task_11> in <method_2> .	2 6 1 13 -1 10 13 -1 3 4 13 -1 8 13 -1 13 -1 5 15 13 -1 7 14 17 18 19 13 -1 0 12 9 16 13 -1
Closest Pairs Data Selection for Support Vector Machines .	support vector machines ; support vectors ; data selection procedures ; decision boundary ; training component	<method> <method> <method> <otherscientificterm> <method>	2 0 0	this paper presents <method_2> for <method_0> . the purpose of <method_2> is to reduce the dataset by eliminating as many non support vectors -lrb- non-svs -rrb- as possible . based on the fact that <method_1> are those vectors close to the <otherscientificterm_3> , <method_2> keeps only the closest pair vectors of opposite classes . the selected dataset will replace the full dataset as the <method_4> for any standard <method_0> .	2 0 6 5 -1 5 -1 1 3 5 -1 4 5 -1
Approximate infinite-dimensional Region Covariance Descriptors for image classification .	symmetric positive definite matrices ; infinite-dimensional region covariance descriptors ; random fourier features ; image classification task ; nyström method ; feature mappings ; infinite-dimensional rcovds ; low-dimensional counterparts ; discriminatory power ; low-dimensional rcovds ; riemannian structure	<otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	2 6 5 ; 6 0 3 ; 2 1 4 ; 6 4 7 ; 9 0 3 ; 4 6 5	we introduce methods to estimate <method_1> by exploiting two <method_5> , namely <otherscientificterm_2> and the <method_4> . in general , <method_6> offer better <otherscientificterm_8> over their <otherscientificterm_7> . however , the underlying <otherscientificterm_10> , i.e. , the manifold of <otherscientificterm_0> , is out of reach to great extent for <method_6> . to overcome this difficulty , we propose to approximate the <method_6> by making use of the aforementioned explicit mappings . we will empirically show that the proposed finite-dimensional approximations of <method_6> consistently outperform the <method_9> for <task_3> , while enjoying the <otherscientificterm_10> of the <otherscientificterm_0> . moreover , our methods achieve the state-of-the-art performance on three different <task_3> .	1 5 2 4 12 14 17 11 -1 6 8 7 15 11 -1 10 0 11 -1 11 -1 9 3 13 16 11 -1 11 -1
Improving Recognition of Novel Input with Similarity .	machine learning tasks ; images of signs ; printed character recognition ; dissimilarity information ; probabilistic framework ; computer vision ; information sources ; unre-coverable errors ; natural scenes ; prior identity ; overall accuracy ; printed font ; speaker ; recognition	<task> <material> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <metric> <material> <method> <task>	5 1 0 ; 3 3 4	many sources of information relevant to <task_5> and <task_0> are often underused . one example is the similarity between the elements from a novel source , such as a <method_12> , writer , or <material_11> . by comparing instances emitted by a source , we help ensure that similar instances are given the same label . previous approaches have clustered instances prior to <task_13> . we propose a <method_4> that unifies similarity with <otherscientificterm_9> and contextual information . by fusing <otherscientificterm_6> in a single model , we eliminate <otherscientificterm_7> that result from processing the information in separate stages and improve <metric_10> . the <method_4> also naturally integrates <otherscientificterm_3> , which has previously been ignored . we demonstrate with an application in <task_2> from <material_1> in <material_8> .	5 0 15 14 -1 12 11 14 -1 14 -1 13 14 -1 4 9 14 -1 6 7 14 -1 10 16 14 -1 3 14 -1
Relaxation of particle image velocimetry based on single autocorrelation of filtered motion blurring .	online measurement of particles ' velocities ; particle image velocimetry ; analysis of motion blurring of particles ; image and particle properties ; measurement of particle velocities ; 5x5 spatial filters ; multi-scale processing ; measurement setup ; linear time ; linear model ; frame rate ; filter parameters ; measured angle ; low complexity ; measurement analysis ; convolutions ; accuracy	<task> <method> <task> <material> <task> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <metric>	10 0 4 ; 11 1 12	in this article , a technique to relax <method_1> based on the <task_2> is proposed in order to reduce the <otherscientificterm_10> required for <task_4> . another advantage is the relaxation of the requirements of the <otherscientificterm_7> while retaining the principle of <method_14> . this technique is based on <otherscientificterm_15> with <method_5> that can be computed in <otherscientificterm_8> , independently from the contents of the image . due to <task_6> , the technique adapts its parameters autonomously , according to the <material_3> to provide accurate results . the <metric_16> of the results is guaranteed by integrating the <otherscientificterm_11> , the <otherscientificterm_12> and eventually the measured size of the particles into a <method_9> . the <metric_13> and high parallelizability of this method enable the <task_0> .	1 2 10 4 18 17 -1 7 14 17 -1 15 5 8 17 -1 6 3 17 -1 16 11 12 19 17 -1 9 17 -1
Dimensionality reduction and generalization .	kernel principal component analysis ; spectral cut-off regularization ; parameter choice procedure ; supervised learning problems ; projected data ; error estimates ; preprocessing step ; probabilistic estimates ; regularization parameter ; integral operators	<method> <otherscientificterm> <method> <task> <material> <metric> <method> <method> <otherscientificterm> <method>	7 0 5 ; 6 0 3 ; 7 0 9	in this paper we investigate the regularization property of <method_0> , by studying its application as a <method_6> to <task_3> . we show that performing <method_0> and then ordinary least squares on the <material_4> , a procedure known as kernel principal component regression -lrb- kpcr -rrb- , is equivalent to <otherscientificterm_1> , the <otherscientificterm_8> being exactly the number of principal components to keep . using <method_7> for <method_9> we can prove <metric_5> for kpcr and propose a <method_2> allowing to prove consistency of the <method_2> .	0 6 3 12 10 -1 4 1 8 10 -1 7 9 5 2 11 13 10 -1
Coupled Clustering : a Method for Detecting Structural Correspondence .	paradigm and computational framework ; identification of correspondences ; coupled clustering ; topical correspondences ; data clustering ; textual corpora	<method> <task> <method> <otherscientificterm> <method> <material>	2 6 4 ; 5 5 0 ; 0 0 1	this paper proposes a new <method_0> for <task_1> between sub-structures of distinct composite systems . for this , we define and investigate a variant of traditional <method_4> , termed <method_2> , which simultaneously identifies corresponding clusters within two data sets . the presented <method_0> is demonstrated and evaluated for detecting <otherscientificterm_3> in <material_5> .	0 1 9 6 -1 4 2 7 6 -1 3 5 8 6 -1
Learning invariant features for speech separation .	binary mask ; speech intelligibil-ity in noise ; invariant speech features ; unseen noise conditions ; speech separation systems ; kernel space ; supervised learning ; speech separation ; noise conditions ; probabilistic properties ; supervised learning ; noise types ; speech-related information ; features	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 2 2 ; 6 0 0 ; 0 0 1	recent studies on <task_7> show that the ideal <method_0> substantially improves <otherscientificterm_1> . <method_6> can be used to effectively estimate the <method_0> . however , <method_10> has trouble dealing with the situations where the <otherscientificterm_9> of the training data and the test data do not match , resulting in a challenging issue of generalization whereby the system trained under particular <otherscientificterm_8> may not generalize to new <otherscientificterm_8> . we propose to use a novel metric learning method to learn <otherscientificterm_2> in the <otherscientificterm_5> . as the learned <otherscientificterm_13> encode <otherscientificterm_12> that is robust to different <otherscientificterm_11> , the system is expected to generalize to <otherscientificterm_3> . evaluations show the advantage of the proposed approach over other <method_4> .	7 0 1 6 17 14 -1 16 14 -1 10 9 8 14 -1 2 5 15 14 -1 13 12 11 14 -1 3 14 -1
A nonparametric variable clustering model .	dirichlet process variable clustering model ; covariance structure of high dimensional data ; synthetic and gene expression analysis problems ; block-diagonal covariance structures ; bayesian non-parametric approach ; factor analysis models ; disjoint partition ; heuristic methods ; observed variables ; clustering	<method> <material> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method>	5 0 1 ; 4 0 6 ; 0 0 3 ; 2 5 4	factor analysis models effectively summarise the <material_1> , but the solutions are typically hard to interpret . this motivates attempting to find a <otherscientificterm_6> , i.e. a simple <method_9> , of <otherscientificterm_8> into highly correlated subsets . we introduce a <method_4> to this <otherscientificterm_6> , and demonstrate advantages over <method_7> proposed to date . our <method_0> can discover <otherscientificterm_3> in data . we evaluate our <method_4> on both <task_2> .	1 11 10 -1 6 9 8 10 -1 4 7 12 10 -1 0 3 13 10 -1 2 5 14 10 -1
Partial Difference Equations over Graphs : Morphological Processing of Arbitrary Discrete Data .	classical local algebraic and pdes-based morphological methods ; partial difference equations ; partial differential equations ; mathematical morphology ; high-dimensional multivariate unorganized data ; local and nonlocal configurations ; image processing context ; image processing problems ; weighted graphs ; morphological operators ; algebraic set ; mm processing ; nonlocal configurations ; graph	<method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	3 0 7 ; 10 2 7 ; 5 2 9	mathematical morphology -lrb- mm -rrb- offers a wide range of operators to address various <task_7> . these <task_7> can be defined in terms of <otherscientificterm_10> or as <method_2> . in this paper , a novel approach is formalized as a framework of <otherscientificterm_1> on <otherscientificterm_8> . we introduce and analyze <method_9> in <otherscientificterm_5> . our framework recovers <method_0> in <otherscientificterm_6> ; generalizes them for <otherscientificterm_12> and extends them to the treatment of any arbitrary discrete data that can be represented by a <otherscientificterm_13> . it leads to considering a new field of application of <method_11> : the case of <material_4> .	7 15 14 -1 10 2 16 14 -1 1 8 14 -1 9 5 17 14 -1 0 6 12 13 14 -1 11 4 14 -1
Physiologically-inspired feature extraction for emotion recognition .	fisher 's f-ratio and mutual information techniques ; non-uniform sub-band processing method ; non-uniform sub-band processing ; error reduction rate ; feature extraction method ; speech emotion recognition ; speech emotion information ; emotion production mechanism ; emotional recognition ; articulation organs ; emotion information ; emotion features ; emotion recognition ; emotional speech ; features ; physiology	<method> <method> <method> <metric> <method> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <material>	14 0 8 ; 4 0 12 ; 1 0 11 ; 2 0 5	in this paper , we proposed a new <method_4> for <task_12> based on the knowledge of the <method_7> in <material_15> . it was reported by physi-acoustist that <material_13> is differently encoded from the normal speech in terms of <otherscientificterm_9> and that <otherscientificterm_10> in speech is concentrated in different frequencies caused by the different movements of organs -lsb- 4 -rsb- . to apply these findings , in this paper , we first quantified the distribution of <otherscientificterm_6> along with each frequency band by exploiting the <method_0> , and then proposed a <method_1> which is able to extract and emphasize the <otherscientificterm_11> in speech . these extracted <otherscientificterm_14> are finally applied to <task_8> . experimental results in <task_5> showed that the extracted <otherscientificterm_14> using our proposed <method_2> outperform the traditional -lrb- mfcc -rrb- <otherscientificterm_14> , and the average <metric_3> amounts to 16.8 % for <task_5> .	4 12 7 15 18 16 -1 13 9 10 16 -1 6 0 1 11 19 16 -1 17 16 -1 14 8 20 16 -1
Probabilistic Color and Adaptive Multi-Feature Tracking with Dynamically Switched Priority Between Cues .	constant color model based particle filter ; dynamic target model adaptation ; probabilistic multi-cue tracking approach ; vivid online evaluation program ; randomized template tracker ; binary confidence measures ; randomized template tracking ; tracking step ; state estimation ; sequential re-sampling ; cross sampling ; color cue ; quantitative comparisons ; cues ; relock ; switching	<method> <task> <method> <method> <method> <method> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 1 ; 4 1 0 ; 3 0 2 ; 0 0 2 ; 11 0 14 ; 5 0 2 ; 4 0 2	we present a <method_2> constructed by employing a novel <method_4> and a <method_0> . our <method_2> is based on deriving simple <method_5> for each tracker which aid priority based <method_15> between the two fundamental <otherscientificterm_13> for <task_8> . thereby the state of the object is estimated from one of the two distributions associated to the <otherscientificterm_13> at each <otherscientificterm_7> . this <method_15> also brings about interaction between the <otherscientificterm_13> at irregular intervals in the form of <method_10> . within this <method_2> , we tackle the important aspect of <task_1> under <method_6> which , by construction , possesses the ability to adapt to changing object appearances . further , to track the object through occlusions we interrupt <method_9> and achieve <otherscientificterm_14> using the <otherscientificterm_11> . in order to evaluate the efficacy of this <method_2> , we put <method_2> to test against several state of art trackers using the <method_3> and make <otherscientificterm_12> .	2 4 0 18 20 23 16 -1 5 15 13 8 22 16 -1 7 16 -1 10 16 -1 1 6 17 16 -1 21 16 -1 9 14 11 19 16 -1
Autonomous Cross-Domain Knowledge Transfer in Lifelong Policy Gradient Reinforcement Learning .	lifelong reinforcement learning ; cross-domain lifelong rl framework ; lifelong learning agents ; online multi-task learning ; interleaved task domains ; dynamical systems ; cross-domain transfer ; transferable knowledge ; lifelong learning ; projection matrices	<task> <method> <method> <task> <material> <method> <task> <otherscientificterm> <task> <otherscientificterm>	3 0 2 ; 4 0 1 ; 1 0 9	online multi-task learning is an important capability for <method_2> , enabling them to acquire models for diverse tasks over time and rapidly learn new tasks by building upon prior experience . however , recent progress toward <task_0> has been limited to learning from within a single task domain . for truly versatile <task_8> , the agent must be able to autonomously transfer knowledge between different task domains . a few methods for <task_6> have been developed , but these methods are computationally inefficient for scenarios where the agent must learn tasks consecutively . in this paper , we develop the first <method_1> . our <method_1> efficiently optimizes a shared repository of <otherscientificterm_7> and learns <otherscientificterm_9> that specialize that knowledge to different task domains . we provide rigorous theoretical guarantees on the stability of this <method_1> , and empirically evaluate its performance on diverse <method_5> . our results show that the proposed <method_1> can learn effectively from <material_4> and rapidly acquire high performance in new domains .	2 11 10 -1 0 10 -1 8 10 -1 6 10 -1 10 -1 1 13 10 -1 7 9 10 -1 5 12 10 -1
